{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mercari NN-proba.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "IFc3-Nt0OjGz",
        "eJMgJxMH71Xa",
        "T7AUTH1aZ2qH",
        "8pWYCnjVUUJq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTwJVJhfUCyj",
        "colab_type": "text"
      },
      "source": [
        "### Iz eksploratorne\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iGnh1a0aTOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import functools\n",
        "import warnings\n",
        "\n",
        "import matplotlib as mlp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "\n",
        "from keras import backend as K\n",
        "import gc\n",
        "import time\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnCUGemoanxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('train.tsv', sep='\\t')\n",
        "test=pd.read_csv('test.tsv', sep='\\t')\n",
        "\n",
        "data.set_index('train_id', inplace=True) # stavimo da train_id bude indeks, onaj kojeg pandas kreira je nepotreban\n",
        "test.set_index('test_id', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmeqQk7zbHsw",
        "colab_type": "text"
      },
      "source": [
        "\"Mala\" nadopuna missing vrijednosti brand_name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJCXcUAmbOC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brandovi1=data['brand_name']\n",
        "brandovi2=test['brand_name']\n",
        "svi_brandovi1=set(brandovi1.values)\n",
        "svi_brandovi2=set(brandovi1.values)\n",
        "\n",
        "svi_brandovi1 = {x for x in svi_brandovi1 if pd.notna(x)}\n",
        "svi_brandovi2 = {x for x in svi_brandovi1 if pd.notna(x)}\n",
        "\n",
        "svi_brandovi1-={'M', 'K', 'X'}\n",
        "svi_brandovi2-={'M', 'K', 'X'}\n",
        "\n",
        "def trazilica1(objekt):\n",
        "    brand=objekt[0]\n",
        "    ime=objekt[1]\n",
        "    if pd.isna(brand):\n",
        "        for i in svi_brandovi1:\n",
        "            if i in ime:\n",
        "                return i\n",
        "    return brand\n",
        "  \n",
        "def trazilica2(objekt):\n",
        "    brand=objekt[0]\n",
        "    ime=objekt[1]\n",
        "    if pd.isna(brand):\n",
        "        for i in svi_brandovi2:\n",
        "            if i in ime:\n",
        "                return i\n",
        "    return brand\n",
        "data['brand_name']=data[['brand_name', 'name']].apply(trazilica1, axis=1)\n",
        "test['brand_name']=test[['brand_name', 'name']].apply(trazilica2, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8BR2MDOby8-",
        "colab_type": "text"
      },
      "source": [
        "Kako se izboriti s missing vrijednostima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04VEJJc9bWg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def handle_missing_inplace(dataset):\n",
        "    dataset['subcat1'].fillna(value='No Label', inplace=True)\n",
        "    dataset['subcat2'].fillna(value='No Label', inplace=True)\n",
        "    dataset['subcat3'].fillna(value='No Label', inplace=True)\n",
        "    dataset['brand_name'].fillna(value='missing', inplace=True)\n",
        "    dataset['item_description'].fillna(value='No description yet', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcmrXLK1db21",
        "colab_type": "text"
      },
      "source": [
        "Funkcija za odvajanje kategorija"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXLSw59mdbp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_cat(text):\n",
        "    try: return text.split(\"/\")\n",
        "    except: return (\"No Label\", \"No Label\", \"No Label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mfK7BZkdiJl",
        "colab_type": "text"
      },
      "source": [
        "Funkcija za računanje rmsle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9BGP8AkdlHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmsle(y, y_pred):\n",
        "    assert len(y) == len(y_pred)\n",
        "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 \\\n",
        "              for i, pred in enumerate(y_pred)]\n",
        "    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw0cfwYU_JQS",
        "colab_type": "text"
      },
      "source": [
        "Podjela na 3 kategorije."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnqNjrs4-kGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['subcat1'], data['subcat2'], data['subcat3'] = \\\n",
        "zip(*data['category_name'].apply(lambda x: split_cat(x)))\n",
        "data.drop('category_name', axis=1, inplace=True)\n",
        "\n",
        "test['subcat1'], test['subcat2'], test['subcat3'] = \\\n",
        "zip(*test['category_name'].apply(lambda x: split_cat(x)))\n",
        "test.drop('category_name', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOtPXG66_OZM",
        "colab_type": "text"
      },
      "source": [
        "Nadopuna missing vrijednosti"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y46XOdjf-9p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "handle_missing_inplace(data)\n",
        "handle_missing_inplace(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAnkowQ3Bz4J",
        "colab_type": "text"
      },
      "source": [
        "Preprocesiranje kategoričkih varijabli pomoću label encodera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH_hBUcVB104",
        "colab_type": "code",
        "outputId": "20a5f8c1-818a-48c8-ee99-658f01da40ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "le.fit(np.hstack([data.subcat1, test.subcat1]))\n",
        "data.subcat1 = le.transform(data.subcat1)\n",
        "test.subcat1 = le.transform(test.subcat1)\n",
        "\n",
        "le.fit(np.hstack([data.subcat2, test.subcat2]))\n",
        "data.subcat2 = le.transform(data.subcat2)\n",
        "test.subcat2 = le.transform(test.subcat2)\n",
        "\n",
        "le.fit(np.hstack([data.subcat3, test.subcat3]))\n",
        "data.subcat3 = le.transform(data.subcat3)\n",
        "test.subcat3 = le.transform(test.subcat3)\n",
        "\n",
        "le.fit(np.hstack([data.brand_name, test.brand_name]))\n",
        "data.brand_name = le.transform(data.brand_name)\n",
        "test.brand_name = le.transform(test.brand_name)\n",
        "del le\n",
        "\n",
        "data.head(3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>shipping</th>\n",
              "      <th>item_description</th>\n",
              "      <th>subcat1</th>\n",
              "      <th>subcat2</th>\n",
              "      <th>subcat3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
              "      <td>3</td>\n",
              "      <td>2917</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>5</td>\n",
              "      <td>103</td>\n",
              "      <td>774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
              "      <td>3</td>\n",
              "      <td>3889</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0</td>\n",
              "      <td>This keyboard is in great condition and works ...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVA-VIV Blouse</td>\n",
              "      <td>1</td>\n",
              "      <td>4588</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
              "      <td>10</td>\n",
              "      <td>104</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         name  ...  subcat3\n",
              "train_id                                       ...         \n",
              "0         MLB Cincinnati Reds T Shirt Size XL  ...      774\n",
              "1            Razer BlackWidow Chroma Keyboard  ...      215\n",
              "2                              AVA-VIV Blouse  ...       97\n",
              "\n",
              "[3 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZVjiUhQzB9V",
        "colab_type": "text"
      },
      "source": [
        "E sad želimo tokenizirati tekstualne podatke. To ćemo napraviti prvo pomoću tokenizera iz keras.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3-hY7RUzHSj",
        "colab_type": "code",
        "outputId": "4b066ecc-7fea-4904-b546-2a0593c7f568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "print(\"Text to seq process...\")\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "raw_text = np.hstack([data.item_description.str.lower(), data.name.str.lower()])\n",
        "\n",
        "print(\"   Fitting tokenizer...\")\n",
        "tok_raw = Tokenizer()\n",
        "tok_raw.fit_on_texts(raw_text)\n",
        "print(\"   Transforming text to seq...\")\n",
        "\n",
        "data[\"seq_item_description\"] = tok_raw.texts_to_sequences(data.item_description.str.lower())\n",
        "test[\"seq_item_description\"] = tok_raw.texts_to_sequences(test.item_description.str.lower())\n",
        "data[\"seq_name\"] = tok_raw.texts_to_sequences(data.name.str.lower())\n",
        "test[\"seq_name\"] = tok_raw.texts_to_sequences(test.name.str.lower())\n",
        "data.head(3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to seq process...\n",
            "   Fitting tokenizer...\n",
            "   Transforming text to seq...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>shipping</th>\n",
              "      <th>item_description</th>\n",
              "      <th>subcat1</th>\n",
              "      <th>subcat2</th>\n",
              "      <th>subcat3</th>\n",
              "      <th>seq_item_description</th>\n",
              "      <th>seq_name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
              "      <td>3</td>\n",
              "      <td>2917</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>5</td>\n",
              "      <td>103</td>\n",
              "      <td>774</td>\n",
              "      <td>[12, 68, 79]</td>\n",
              "      <td>[3852, 8823, 6896, 208, 84, 6, 155]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
              "      <td>3</td>\n",
              "      <td>3889</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0</td>\n",
              "      <td>This keyboard is in great condition and works ...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>215</td>\n",
              "      <td>[29, 2627, 10, 7, 39, 17, 1, 207, 51, 19, 1113...</td>\n",
              "      <td>[10760, 25565, 16369, 2627]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVA-VIV Blouse</td>\n",
              "      <td>1</td>\n",
              "      <td>4588</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
              "      <td>10</td>\n",
              "      <td>104</td>\n",
              "      <td>97</td>\n",
              "      <td>[604, 60, 9, 4, 5347, 11, 192, 1, 4, 886, 1290...</td>\n",
              "      <td>[7634, 10563, 666]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         name  ...                             seq_name\n",
              "train_id                                       ...                                     \n",
              "0         MLB Cincinnati Reds T Shirt Size XL  ...  [3852, 8823, 6896, 208, 84, 6, 155]\n",
              "1            Razer BlackWidow Chroma Keyboard  ...          [10760, 25565, 16369, 2627]\n",
              "2                              AVA-VIV Blouse  ...                   [7634, 10563, 666]\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQdL2Z5I3O7z",
        "colab_type": "text"
      },
      "source": [
        "Kao varijable seq_item_description i seq_name dobili smo nizove, nećemo uzeti najveću moguću veličinu, već onu u koju spada većina nizova; zato nam je potrebna ova analiza, da vidimo koja je najveća potrebna veličina za embeddanje."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv9BiSNk3tQl",
        "colab_type": "code",
        "outputId": "9dfe2931-cfb9-4c8c-87c8-03fd3d5a3b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "max_name_seq = np.max([np.max(data.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\n",
        "max_seq_item_description = np.max([np.max(data.seq_item_description.apply(lambda x: len(x)))\n",
        "                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\n",
        "print(\"max name seq \"+str(max_name_seq))\n",
        "print(\"max item desc seq \"+str(max_seq_item_description))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max name seq 17\n",
            "max item desc seq 269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9VzqvDm34Ma",
        "colab_type": "code",
        "outputId": "8f302459-ac54-4e67-e6b0-f45f76146d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "data.seq_name.apply(lambda x: len(x)).hist()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6769b91e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e45s6RnN38yp",
        "colab_type": "code",
        "outputId": "bc591cc6-0315-4c74-e9ff-7a8e63766c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "data.seq_item_description.apply(lambda x: len(x)).hist()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f675fdc6470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nARx3+5Gt7yDPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pS09_P-3_Wj",
        "colab_type": "text"
      },
      "source": [
        "Vidimo da nam je dovoljno uzeti MAX_NAME_SEQ = 10 i MAX_ITEM_DESC_SEQ = 75"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oIYI_us4Jei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NAME_SEQ = 8\n",
        "MAX_ITEM_DESC_SEQ = 75\n",
        "MAX_TEXT = np.max([np.max(data.seq_name.max())\n",
        "                   , np.max(test.seq_name.max())\n",
        "                  , np.max(data.seq_item_description.max())\n",
        "                  , np.max(test.seq_item_description.max())])+2\n",
        "MAX_CAT1 = np.max([data.subcat1.max(), test.subcat1.max()])+1\n",
        "MAX_CAT2 = np.max([data.subcat2.max(), test.subcat2.max()])+1\n",
        "MAX_CAT3 = np.max([data.subcat3.max(), test.subcat3.max()])+1\n",
        "\n",
        "MAX_BRAND = np.max([data.brand_name.max(), test.brand_name.max()])+1\n",
        "MAX_CONDITION = np.max([data.item_condition_id.max(), test.item_condition_id.max()])+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJmstaDE6iZ7",
        "colab_type": "text"
      },
      "source": [
        "Scaleamo target varijablu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgabavnx6mch",
        "colab_type": "code",
        "outputId": "e8fddd05-55a6-4410-9b71-e9f463a40615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "data[\"target\"] = np.log(data.price+1)\n",
        "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "data[\"target\"] = target_scaler.fit_transform(data.target.values.reshape(-1,1))\n",
        "pd.DataFrame(data.target).hist()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f675d5e7780>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXDTMzCzb/wcFitdPP2LzHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9ij3ego6zQK",
        "colab_type": "code",
        "outputId": "22256472-a8b0-4c10-dc92-3999e4268f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "dtrain, dvalid = train_test_split(data, random_state=42, train_size=0.95)\n",
        "print(dtrain.shape)\n",
        "print(dvalid.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1408408, 12)\n",
            "(74127, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOtTmtS968Ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KERAS DATA DEFINITION\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def get_keras_data(dataset):\n",
        "    X = {\n",
        "        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n",
        "        ,'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ)\n",
        "        ,'brand_name': np.array(dataset.brand_name)\n",
        "        ,'subcat1': np.array(dataset.subcat1)\n",
        "        ,'subcat2': np.array(dataset.subcat2)\n",
        "        ,'subcat3': np.array(dataset.subcat3)\n",
        "        ,'item_condition': np.array(dataset.item_condition_id)\n",
        "        ,'num_vars': np.array(dataset[[\"shipping\"]])\n",
        "    }\n",
        "    return X\n",
        "\n",
        "X_train = get_keras_data(dtrain)\n",
        "X_valid = get_keras_data(dvalid)\n",
        "X_test = get_keras_data(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNkXi6iUm7jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras import backend as K\n",
        "\n",
        "def get_callbacks(filepath, patience=2):\n",
        "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
        "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
        "    return [es, msave]\n",
        "\n",
        "def rmsle_cust(y_true, y_pred):\n",
        "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
        "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
        "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFc3-Nt0OjGz",
        "colab_type": "text"
      },
      "source": [
        "### Modeli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqtilAtl7RFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    #params\n",
        "    dr_r = 0.1\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
        "    emb_subcat1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat2 = Embedding(MAX_CAT2, 10)(subcat2)\n",
        "    emb_subcat3 = Embedding(MAX_CAT3, 10)(subcat3)\n",
        "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
        "    \n",
        "    #rnn layer\n",
        "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
        "    rnn_layer2 = GRU(8) (emb_name)\n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name)\n",
        "        , Flatten() (emb_subcat1)\n",
        "        , Flatten() (emb_subcat2)\n",
        "        , Flatten() (emb_subcat3)\n",
        "        , Flatten() (emb_item_condition)\n",
        "        , rnn_layer1\n",
        "        , rnn_layer2\n",
        "        , num_vars\n",
        "    ])\n",
        "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model\n",
        "\n",
        "    \n",
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG9A03G89GK7",
        "colab_type": "code",
        "outputId": "961ff7ad-8e6a-4523-bf35-98c534ad66ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "dtrain.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>shipping</th>\n",
              "      <th>item_description</th>\n",
              "      <th>subcat1</th>\n",
              "      <th>subcat2</th>\n",
              "      <th>subcat3</th>\n",
              "      <th>seq_item_description</th>\n",
              "      <th>seq_name</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>407853</th>\n",
              "      <td>maroon velvet lisette shorts</td>\n",
              "      <td>1</td>\n",
              "      <td>737</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>brand new from brandy melville</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>706</td>\n",
              "      <td>[16, 5, 43, 536, 587]</td>\n",
              "      <td>[836, 1038, 18025, 129]</td>\n",
              "      <td>-0.175509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748699</th>\n",
              "      <td>Benefit Roller Lash Mascara FULL SIZE</td>\n",
              "      <td>2</td>\n",
              "      <td>574</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Benefit Roller Lash Mascara FULL SIZE in the c...</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>301</td>\n",
              "      <td>[1232, 2593, 1292, 643, 152, 6, 7, 2, 48, 24, ...</td>\n",
              "      <td>[1232, 2593, 1292, 643, 152, 6]</td>\n",
              "      <td>-0.287907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320295</th>\n",
              "      <td>Holographic Ipsy Bag</td>\n",
              "      <td>2</td>\n",
              "      <td>5265</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Used once</td>\n",
              "      <td>10</td>\n",
              "      <td>112</td>\n",
              "      <td>223</td>\n",
              "      <td>[31, 96]</td>\n",
              "      <td>[2875, 2240, 101]</td>\n",
              "      <td>-0.453202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094144</th>\n",
              "      <td>Samsung galaxy on5 10/10 con. W/metropcs</td>\n",
              "      <td>2</td>\n",
              "      <td>4121</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1</td>\n",
              "      <td>No description yet</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>178</td>\n",
              "      <td>[12, 68, 79]</td>\n",
              "      <td>[440, 438, 12298, 95, 95, 3901, 245, 11128]</td>\n",
              "      <td>-0.023501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1310650</th>\n",
              "      <td>Country Heat</td>\n",
              "      <td>2</td>\n",
              "      <td>5265</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Comes with 4 DVDs and a bonus DVD. Also comes ...</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>240</td>\n",
              "      <td>[103, 9, 47, 2354, 1, 4, 2205, 699, 154, 103, ...</td>\n",
              "      <td>[2215, 1160]</td>\n",
              "      <td>-0.114556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              name  ...    target\n",
              "train_id                                            ...          \n",
              "407853                maroon velvet lisette shorts  ... -0.175509\n",
              "748699       Benefit Roller Lash Mascara FULL SIZE  ... -0.287907\n",
              "320295                        Holographic Ipsy Bag  ... -0.453202\n",
              "1094144   Samsung galaxy on5 10/10 con. W/metropcs  ... -0.023501\n",
              "1310650                               Country Heat  ... -0.114556\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8F9V5198NPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 20000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-x7ksW7Ie3G",
        "colab_type": "text"
      },
      "source": [
        "Greške na training skupu nakon 5.epohe:\n",
        "loss: 0.0146 - mean_absolute_error: 0.0914 - rmsle_cust: 0.0120 - val_loss: 0.0154 - val_mean_absolute_error: 0.0932 - val_rmsle_cust: 0.0125"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeE4w_t1EWtg",
        "colab_type": "text"
      },
      "source": [
        "Evaluiramo model na validacijskom skupu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCNu0iHbEVqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EVALUATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzOlAxQ1SxKz",
        "colab_type": "text"
      },
      "source": [
        " RMSLE na validacijskom: 0.4855084693671954\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9g_W14NJLJp",
        "colab_type": "text"
      },
      "source": [
        "Idem isprobati malo drukčije:\n",
        "smanjit ćemo batch size, staviti 5 epoha i dalje, dodati još jedan layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuRHDma3JZBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model1():\n",
        "    #params\n",
        "    dr_r = 0.1\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 64)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 64)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 16)(brand_name)\n",
        "    emb_subcat1 = Embedding(MAX_CAT1, 16)(subcat1)\n",
        "    emb_subcat2 = Embedding(MAX_CAT2, 16)(subcat2)\n",
        "    emb_subcat3 = Embedding(MAX_CAT3, 16)(subcat3)\n",
        "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
        "    \n",
        "    #rnn layer\n",
        "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
        "    rnn_layer2 = GRU(8) (emb_name)\n",
        "    rnn_layer3 = GRU(4)(emb_brand_name) \n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        rnn_layer3\n",
        "        , Flatten() (emb_subcat1)\n",
        "        , Flatten() (emb_subcat2)\n",
        "        , Flatten() (emb_subcat3)\n",
        "        , Flatten() (emb_item_condition)\n",
        "        , rnn_layer1\n",
        "        , rnn_layer2\n",
        "        , num_vars\n",
        "    ])\n",
        "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQqBEOq-KPCw",
        "colab_type": "code",
        "outputId": "7fbda011-edb0-41b1-c831-4cb6dc631ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1303
        }
      },
      "source": [
        "model = get_model1()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "brand_name (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_condition (InputLayer)     (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_desc (InputLayer)          (None, 75)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "name (InputLayer)               (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_17 (Embedding)        (None, 1, 16)        84640       brand_name[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 1, 16)        176         subcat1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_19 (Embedding)        (None, 1, 16)        1824        subcat2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_20 (Embedding)        (None, 1, 16)        14128       subcat3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_21 (Embedding)        (None, 1, 5)         30          item_condition[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "embedding_16 (Embedding)        (None, 75, 64)       16581632    item_desc[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_15 (Embedding)        (None, 10, 64)       16581632    name[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "gru_7 (GRU)                     (None, 4)            252         embedding_17[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 16)           0           embedding_18[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_12 (Flatten)            (None, 16)           0           embedding_19[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 16)           0           embedding_20[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 5)            0           embedding_21[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "gru_5 (GRU)                     (None, 16)           3888        embedding_16[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "gru_6 (GRU)                     (None, 8)            1752        embedding_15[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "num_vars (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 82)           0           gru_7[0][0]                      \n",
            "                                                                 flatten_11[0][0]                 \n",
            "                                                                 flatten_12[0][0]                 \n",
            "                                                                 flatten_13[0][0]                 \n",
            "                                                                 flatten_14[0][0]                 \n",
            "                                                                 gru_5[0][0]                      \n",
            "                                                                 gru_6[0][0]                      \n",
            "                                                                 num_vars[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 128)          10624       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 64)           0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1)            65          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 33,288,899\n",
            "Trainable params: 33,288,899\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNsoNOCRKKng",
        "colab_type": "code",
        "outputId": "3103dd74-2392-45dd-c6e1-7a1625c5e889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model1()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1408408 samples, validate on 74127 samples\n",
            "Epoch 1/5\n",
            "1408408/1408408 [==============================] - 370s 263us/step - loss: 0.0287 - mean_absolute_error: 0.1263 - rmsle_cust: 0.0161 - val_loss: 0.0175 - val_mean_absolute_error: 0.0999 - val_rmsle_cust: 0.0134\n",
            "Epoch 2/5\n",
            "1408408/1408408 [==============================] - 356s 253us/step - loss: 0.0174 - mean_absolute_error: 0.0997 - rmsle_cust: 0.0130 - val_loss: 0.0162 - val_mean_absolute_error: 0.0959 - val_rmsle_cust: 0.0129\n",
            "Epoch 3/5\n",
            "1408408/1408408 [==============================] - 362s 257us/step - loss: 0.0154 - mean_absolute_error: 0.0940 - rmsle_cust: 0.0123 - val_loss: 0.0153 - val_mean_absolute_error: 0.0933 - val_rmsle_cust: 0.0125\n",
            "Epoch 4/5\n",
            "1408408/1408408 [==============================] - 374s 265us/step - loss: 0.0143 - mean_absolute_error: 0.0903 - rmsle_cust: 0.0119 - val_loss: 0.0151 - val_mean_absolute_error: 0.0924 - val_rmsle_cust: 0.0123\n",
            "Epoch 5/5\n",
            "1408408/1408408 [==============================] - 364s 258us/step - loss: 0.0134 - mean_absolute_error: 0.0874 - rmsle_cust: 0.0115 - val_loss: 0.0149 - val_mean_absolute_error: 0.0918 - val_rmsle_cust: 0.0122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00318f4898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVAag6YOahPJ",
        "colab_type": "text"
      },
      "source": [
        "Greške na training skupu: \n",
        "loss: 0.0133 - mean_absolute_error: 0.0868 - rmsle_cust: 0.0115 - val_loss: 0.0150 - val_mean_absolute_error: 0.0929 - val_rmsle_cust: 0.0122"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ku4cUy_Kvty",
        "colab_type": "code",
        "outputId": "445792d7-e0d9-48be-b393-d247c28eafc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.47965386188750087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxd_KFIhTNIn",
        "colab_type": "text"
      },
      "source": [
        "RMSLE na validacijskom: 0.4787711738282493"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq9hmbMoVc_Q",
        "colab_type": "text"
      },
      "source": [
        "Ispalo je ponešto bolje. Što ako još smanjim batch size?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5JEwYALViWo",
        "colab_type": "code",
        "outputId": "865c92d3-3fd9-469c-e3fd-5b0f8f07e38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 5000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model1()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1467709 samples, validate on 14826 samples\n",
            "Epoch 1/5\n",
            "1467709/1467709 [==============================] - 552s 376us/step - loss: 0.0206 - mean_absolute_error: 0.1081 - rmsle_cust: 0.0138 - val_loss: 0.0158 - val_mean_absolute_error: 0.0951 - val_rmsle_cust: 0.0126\n",
            "Epoch 2/5\n",
            "1467709/1467709 [==============================] - 548s 373us/step - loss: 0.0152 - mean_absolute_error: 0.0933 - rmsle_cust: 0.0123 - val_loss: 0.0152 - val_mean_absolute_error: 0.0940 - val_rmsle_cust: 0.0122\n",
            "Epoch 3/5\n",
            "1467709/1467709 [==============================] - 548s 373us/step - loss: 0.0141 - mean_absolute_error: 0.0894 - rmsle_cust: 0.0118 - val_loss: 0.0149 - val_mean_absolute_error: 0.0927 - val_rmsle_cust: 0.0123\n",
            "Epoch 4/5\n",
            "1467709/1467709 [==============================] - 547s 373us/step - loss: 0.0131 - mean_absolute_error: 0.0862 - rmsle_cust: 0.0114 - val_loss: 0.0148 - val_mean_absolute_error: 0.0921 - val_rmsle_cust: 0.0121\n",
            "Epoch 5/5\n",
            "1467709/1467709 [==============================] - 546s 372us/step - loss: 0.0123 - mean_absolute_error: 0.0834 - rmsle_cust: 0.0109 - val_loss: 0.0147 - val_mean_absolute_error: 0.0915 - val_rmsle_cust: 0.0120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f390dd3ef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh6_Fs5_ZXMq",
        "colab_type": "text"
      },
      "source": [
        "Greška na test skupu:\n",
        "loss: 0.0123 - mean_absolute_error: 0.0834 - rmsle_cust: 0.0109 - val_loss: 0.0147 - val_mean_absolute_error: 0.0915 - val_rmsle_cust: 0.0120\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtuq0eZ8WJHw",
        "colab_type": "code",
        "outputId": "f781ba72-acf5-4fd0-cbd5-75a85c1b66ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.4771689923714617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9YdjQm-j5G6",
        "colab_type": "text"
      },
      "source": [
        "RMSLE na validacijskom: 0.4771689923714617"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_GeEyKGXHcP",
        "colab_type": "text"
      },
      "source": [
        "Što se dogodi ako ubacim još koji dropout?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTitzgD5XGA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model2():\n",
        "    #params\n",
        "    dr_r = 0.1\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
        "    emb_subcat1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat2 = Embedding(MAX_CAT2, 10)(subcat2)\n",
        "    emb_subcat3 = Embedding(MAX_CAT3, 10)(subcat3)\n",
        "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
        "    \n",
        "    #rnn layer\n",
        "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
        "    rnn_layer2 = GRU(8) (emb_name)\n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name)\n",
        "        , Flatten() (emb_subcat1)\n",
        "        , Flatten() (emb_subcat2)\n",
        "        , Flatten() (emb_subcat3)\n",
        "        , Flatten() (emb_item_condition)\n",
        "        , rnn_layer1\n",
        "        , rnn_layer2\n",
        "        , num_vars\n",
        "    ])\n",
        "    \n",
        "    main_l = Dropout(0.3)(Dense(512,kernel_initializer='normal',activation='relu') (main_l))\n",
        "    main_l = Dropout(0.3)(Dense(256,kernel_initializer='normal',activation='relu') (main_l))\n",
        "    main_l = Dropout(0.3)(Dense(128,kernel_initializer='normal',activation='relu') (main_l))\n",
        "    main_l = Dropout(0.3)(Dense(64,kernel_initializer='normal',activation='relu') (main_l))\n",
        "\n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model\n",
        "\n",
        "    \n",
        "model = get_model2()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RySIvyNnZuII",
        "colab_type": "code",
        "outputId": "b645b85a-b4f2-4bb3-ae6a-db5b9965d949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model2()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1467709 samples, validate on 14826 samples\n",
            "Epoch 1/5\n",
            "1467709/1467709 [==============================] - 438s 298us/step - loss: 0.0261 - mean_absolute_error: 0.1224 - rmsle_cust: 0.0163 - val_loss: 0.0186 - val_mean_absolute_error: 0.1035 - val_rmsle_cust: 0.0161\n",
            "Epoch 2/5\n",
            "1467709/1467709 [==============================] - 427s 291us/step - loss: 0.0184 - mean_absolute_error: 0.1022 - rmsle_cust: 0.0161 - val_loss: 0.0172 - val_mean_absolute_error: 0.0995 - val_rmsle_cust: 0.0155\n",
            "Epoch 3/5\n",
            "1467709/1467709 [==============================] - 419s 286us/step - loss: 0.0170 - mean_absolute_error: 0.0979 - rmsle_cust: 0.0153 - val_loss: 0.0157 - val_mean_absolute_error: 0.0938 - val_rmsle_cust: 0.0149\n",
            "Epoch 4/5\n",
            "1467709/1467709 [==============================] - 428s 292us/step - loss: 0.0159 - mean_absolute_error: 0.0947 - rmsle_cust: 0.0146 - val_loss: 0.0153 - val_mean_absolute_error: 0.0923 - val_rmsle_cust: 0.0143\n",
            "Epoch 5/5\n",
            "1467709/1467709 [==============================] - 426s 290us/step - loss: 0.0151 - mean_absolute_error: 0.0924 - rmsle_cust: 0.0140 - val_loss: 0.0149 - val_mean_absolute_error: 0.0904 - val_rmsle_cust: 0.0140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52d236dd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDINTX-lUI0h",
        "colab_type": "text"
      },
      "source": [
        "Greška na training skupu: \n",
        "loss: 0.0151 - mean_absolute_error: 0.0924 - rmsle_cust: 0.0140 - val_loss: 0.0149 - val_mean_absolute_error: 0.0904 - val_rmsle_cust: 0.0140"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf_oz_RSZ2R_",
        "colab_type": "code",
        "outputId": "5de884aa-2b7d-4d63-949d-13e59cf919f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.4781637090029327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbdqZjRQUU6g",
        "colab_type": "text"
      },
      "source": [
        " RMSLE na validacijskom: 0.4781637090029327\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Wh5UpmkEOJ",
        "colab_type": "text"
      },
      "source": [
        "Ako ubacimo još koji dropuot, ostaje otprilike isti rezultat, a vrijeme je jednako veliko"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpMlWWoXhNOu",
        "colab_type": "text"
      },
      "source": [
        "Ako povećamo embedding faktore, što će se dogoditi?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZchUGXZhCiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model4():\n",
        "    #params\n",
        "    dr_r = 0.1\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 128)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 64)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 64)(brand_name)\n",
        "    emb_subcat1 = Embedding(MAX_CAT1, 32)(subcat1)\n",
        "    emb_subcat2 = Embedding(MAX_CAT2, 32)(subcat2)\n",
        "    emb_subcat3 = Embedding(MAX_CAT3, 32)(subcat3)\n",
        "    emb_item_condition = Embedding(MAX_CONDITION, 8)(item_condition)\n",
        "    \n",
        "    #rnn layer\n",
        "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
        "    rnn_layer2 = GRU(8) (emb_name)\n",
        "    rnn_layer3 = GRU(4)(emb_brand_name) \n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        rnn_layer3\n",
        "        , Flatten() (emb_subcat1)\n",
        "        , Flatten() (emb_subcat2)\n",
        "        , Flatten() (emb_subcat3)\n",
        "        , Flatten() (emb_item_condition)\n",
        "        , rnn_layer1\n",
        "        , rnn_layer2\n",
        "        , num_vars\n",
        "    ])\n",
        "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model\n",
        "  \n",
        "model = get_model4()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaHP6R0ThUGr",
        "colab_type": "code",
        "outputId": "ef2046c6-7a1f-466f-ab57-fcb0dd3ecc3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 10\n",
        "\n",
        "model = get_model4()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1467709 samples, validate on 14826 samples\n",
            "Epoch 1/10\n",
            "1467709/1467709 [==============================] - 458s 312us/step - loss: 0.0228 - mean_absolute_error: 0.1140 - rmsle_cust: 0.0143 - val_loss: 0.0164 - val_mean_absolute_error: 0.0972 - val_rmsle_cust: 0.0128\n",
            "Epoch 2/10\n",
            "1467709/1467709 [==============================] - 449s 306us/step - loss: 0.0160 - mean_absolute_error: 0.0956 - rmsle_cust: 0.0126 - val_loss: 0.0153 - val_mean_absolute_error: 0.0940 - val_rmsle_cust: 0.0124\n",
            "Epoch 3/10\n",
            "1467709/1467709 [==============================] - 453s 309us/step - loss: 0.0147 - mean_absolute_error: 0.0917 - rmsle_cust: 0.0121 - val_loss: 0.0151 - val_mean_absolute_error: 0.0935 - val_rmsle_cust: 0.0123\n",
            "Epoch 4/10\n",
            "1467709/1467709 [==============================] - 455s 310us/step - loss: 0.0139 - mean_absolute_error: 0.0890 - rmsle_cust: 0.0117 - val_loss: 0.0149 - val_mean_absolute_error: 0.0930 - val_rmsle_cust: 0.0121\n",
            "Epoch 5/10\n",
            "1467709/1467709 [==============================] - 448s 305us/step - loss: 0.0131 - mean_absolute_error: 0.0864 - rmsle_cust: 0.0113 - val_loss: 0.0149 - val_mean_absolute_error: 0.0925 - val_rmsle_cust: 0.0122\n",
            "Epoch 6/10\n",
            "1467709/1467709 [==============================] - 448s 305us/step - loss: 0.0126 - mean_absolute_error: 0.0843 - rmsle_cust: 0.0110 - val_loss: 0.0147 - val_mean_absolute_error: 0.0919 - val_rmsle_cust: 0.0121\n",
            "Epoch 7/10\n",
            "1467709/1467709 [==============================] - 467s 318us/step - loss: 0.0120 - mean_absolute_error: 0.0823 - rmsle_cust: 0.0107 - val_loss: 0.0147 - val_mean_absolute_error: 0.0919 - val_rmsle_cust: 0.0120\n",
            "Epoch 8/10\n",
            "1467709/1467709 [==============================] - 474s 323us/step - loss: 0.0116 - mean_absolute_error: 0.0805 - rmsle_cust: 0.0104 - val_loss: 0.0147 - val_mean_absolute_error: 0.0914 - val_rmsle_cust: 0.0120\n",
            "Epoch 9/10\n",
            "1467709/1467709 [==============================] - 483s 329us/step - loss: 0.0112 - mean_absolute_error: 0.0790 - rmsle_cust: 0.0101 - val_loss: 0.0146 - val_mean_absolute_error: 0.0912 - val_rmsle_cust: 0.0120\n",
            "Epoch 10/10\n",
            "1467709/1467709 [==============================] - 469s 319us/step - loss: 0.0108 - mean_absolute_error: 0.0776 - rmsle_cust: 0.0099 - val_loss: 0.0148 - val_mean_absolute_error: 0.0916 - val_rmsle_cust: 0.0122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63eaa14e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUJJiBoYHKRR",
        "colab_type": "text"
      },
      "source": [
        "Greška na training skupu: loss: 0.0130 - mean_absolute_error: 0.0860 - rmsle_cust: 0.0113 - val_loss: 0.0146 - val_mean_absolute_error: 0.0916 - val_rmsle_cust: 0.0120"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANChH7xKhi6L",
        "colab_type": "code",
        "outputId": "7d7d1ee0-607f-4113-8185-11f0e8222f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.4809565860698974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BMqjiD7HXip",
        "colab_type": "text"
      },
      "source": [
        "Nakon 5 epoha: RMSLE na validacijskom: 0.474487655036319\n",
        "\n",
        "Nakon 10 epoha:  RMSLE na validacijskom: 0.4809565860698974 \n",
        "pogorša se!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir_wvP4NXl2x",
        "colab_type": "text"
      },
      "source": [
        "Dodajemo nekoliko dense layera s aktivacijom relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRg7kXNfKQ4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1289
        },
        "outputId": "7f6f7299-61f8-4224-aa43-0ae9ecdd0202"
      },
      "source": [
        "def get_model5():    \n",
        "    # Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
        "\n",
        "    # Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
        "    emb_subcat1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat2 = Embedding(MAX_CAT2, 10)(subcat2)\n",
        "    emb_subcat3 = Embedding(MAX_CAT3, 10)(subcat3)\n",
        "    \n",
        "    # rnn layers\n",
        "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
        "    rnn_layer2 = GRU(8) (emb_name)\n",
        "\n",
        "    # main layers\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name),\n",
        "        Flatten() (emb_subcat1),\n",
        "        Flatten() (emb_subcat2),\n",
        "        Flatten() (emb_subcat3),\n",
        "        item_condition,\n",
        "        rnn_layer1,\n",
        "        rnn_layer2,\n",
        "        num_vars,\n",
        "    ])\n",
        "\n",
        "    main_l = Dense(256)(main_l)\n",
        "    main_l = Activation('elu')(main_l)\n",
        "\n",
        "    main_l = Dense(128)(main_l)\n",
        "    main_l = Activation('elu')(main_l)\n",
        "\n",
        "    main_l = Dense(64)(main_l)\n",
        "    main_l = Activation('elu')(main_l)\n",
        "\n",
        "    # the output layer.\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model5()\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "brand_name (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_desc (InputLayer)          (None, 75)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "name (InputLayer)               (None, 8)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_36 (Embedding)        (None, 1, 10)        52900       brand_name[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_37 (Embedding)        (None, 1, 10)        110         subcat1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_38 (Embedding)        (None, 1, 10)        1140        subcat2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_39 (Embedding)        (None, 1, 10)        8830        subcat3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_35 (Embedding)        (None, 75, 60)       15545280    item_desc[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_34 (Embedding)        (None, 8, 50)        12954400    name[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 10)           0           embedding_36[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_22 (Flatten)            (None, 10)           0           embedding_37[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_23 (Flatten)            (None, 10)           0           embedding_38[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_24 (Flatten)            (None, 10)           0           embedding_39[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "item_condition (InputLayer)     (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gru_5 (GRU)                     (None, 16)           3696        embedding_35[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "gru_6 (GRU)                     (None, 8)            1416        embedding_34[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "num_vars (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 66)           0           flatten_21[0][0]                 \n",
            "                                                                 flatten_22[0][0]                 \n",
            "                                                                 flatten_23[0][0]                 \n",
            "                                                                 flatten_24[0][0]                 \n",
            "                                                                 item_condition[0][0]             \n",
            "                                                                 gru_5[0][0]                      \n",
            "                                                                 gru_6[0][0]                      \n",
            "                                                                 num_vars[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 256)          17152       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 256)          0           dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 128)          32896       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 128)          0           dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 64)           8256        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64)           0           dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 1)            65          activation_9[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 28,626,141\n",
            "Trainable params: 28,626,141\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W60uKDedKR4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "615892c5-17d8-4fd8-8605-ed93bf8b3d9e"
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 10\n",
        "\n",
        "model = get_model5()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1408408 samples, validate on 74127 samples\n",
            "Epoch 1/10\n",
            "1408408/1408408 [==============================] - 367s 261us/step - loss: 0.0313 - mean_absolute_error: 0.1281 - rmsle_cust: 0.0172 - val_loss: 0.0172 - val_mean_absolute_error: 0.0986 - val_rmsle_cust: 0.0134\n",
            "Epoch 2/10\n",
            "1408408/1408408 [==============================] - 363s 258us/step - loss: 0.0156 - mean_absolute_error: 0.0937 - rmsle_cust: 0.0126 - val_loss: 0.0153 - val_mean_absolute_error: 0.0929 - val_rmsle_cust: 0.0126\n",
            "Epoch 3/10\n",
            "1408408/1408408 [==============================] - 360s 255us/step - loss: 0.0140 - mean_absolute_error: 0.0890 - rmsle_cust: 0.0119 - val_loss: 0.0150 - val_mean_absolute_error: 0.0916 - val_rmsle_cust: 0.0123\n",
            "Epoch 4/10\n",
            "1408408/1408408 [==============================] - 360s 255us/step - loss: 0.0131 - mean_absolute_error: 0.0861 - rmsle_cust: 0.0114 - val_loss: 0.0146 - val_mean_absolute_error: 0.0906 - val_rmsle_cust: 0.0121\n",
            "Epoch 5/10\n",
            "1408408/1408408 [==============================] - 358s 254us/step - loss: 0.0124 - mean_absolute_error: 0.0834 - rmsle_cust: 0.0110 - val_loss: 0.0144 - val_mean_absolute_error: 0.0901 - val_rmsle_cust: 0.0119\n",
            "Epoch 6/10\n",
            "1408408/1408408 [==============================] - 358s 254us/step - loss: 0.0117 - mean_absolute_error: 0.0811 - rmsle_cust: 0.0106 - val_loss: 0.0143 - val_mean_absolute_error: 0.0897 - val_rmsle_cust: 0.0119\n",
            "Epoch 7/10\n",
            "1408408/1408408 [==============================] - 371s 263us/step - loss: 0.0112 - mean_absolute_error: 0.0791 - rmsle_cust: 0.0102 - val_loss: 0.0143 - val_mean_absolute_error: 0.0893 - val_rmsle_cust: 0.0118\n",
            "Epoch 8/10\n",
            "1408408/1408408 [==============================] - 352s 250us/step - loss: 0.0108 - mean_absolute_error: 0.0776 - rmsle_cust: 0.0099 - val_loss: 0.0143 - val_mean_absolute_error: 0.0893 - val_rmsle_cust: 0.0119\n",
            "Epoch 9/10\n",
            "1408408/1408408 [==============================] - 361s 256us/step - loss: 0.0104 - mean_absolute_error: 0.0760 - rmsle_cust: 0.0097 - val_loss: 0.0143 - val_mean_absolute_error: 0.0892 - val_rmsle_cust: 0.0119\n",
            "Epoch 10/10\n",
            "1408408/1408408 [==============================] - 353s 251us/step - loss: 0.0101 - mean_absolute_error: 0.0746 - rmsle_cust: 0.0094 - val_loss: 0.0144 - val_mean_absolute_error: 0.0894 - val_rmsle_cust: 0.0120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3be0253c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L90GgCPtKT6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e92161ca-bc22-4014-8655-0b1b75a139bd"
      },
      "source": [
        "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.46906979665411985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tddh4rGT05B",
        "colab_type": "text"
      },
      "source": [
        "nakon 5 epoha:  RMSLE na validacijskom: 0.4708457943897959\n",
        "\n",
        "nakon 10 epoha:  RMSLE na validacijskom: 0.46906979665411985\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx7hc4igV21t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 1000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model5()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0oDNbtaV4_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfjyzQIlV7Jy",
        "colab_type": "text"
      },
      "source": [
        " RMSLE na validacijskom: 0.46891520472053166"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYrs9NYeZyi4",
        "colab_type": "text"
      },
      "source": [
        "Zašto ne isprobati dodavanje još kojeg sloja, možda s nekom drugom aktivacijskom funkcijom?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq15L2MFz_i8",
        "colab_type": "text"
      },
      "source": [
        "# Najbolji model za sad!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7siE3GpZ431",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1361
        },
        "outputId": "97f37ec8-3054-4c56-8e65-2a036acb6e42"
      },
      "source": [
        "def get_model6():    \n",
        "    # Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
        "\n",
        "    # Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
        "    emb_subcat1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat2 = Embedding(MAX_CAT2, 10)(subcat2)\n",
        "    emb_subcat3 = Embedding(MAX_CAT3, 10)(subcat3)\n",
        "    \n",
        "    # rnn layers\n",
        "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
        "    rnn_layer2 = GRU(8) (emb_name)\n",
        "\n",
        "    # main layers\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name),\n",
        "        Flatten() (emb_subcat1),\n",
        "        Flatten() (emb_subcat2),\n",
        "        Flatten() (emb_subcat3),\n",
        "        item_condition,\n",
        "        rnn_layer1,\n",
        "        rnn_layer2,\n",
        "        num_vars,\n",
        "    ])\n",
        "    \n",
        "    main_l = Dense(512)(main_l)\n",
        "    main_l = Activation('relu')(main_l)\n",
        "    \n",
        "    main_l = Dense(256)(main_l)\n",
        "    main_l = Activation('relu')(main_l)\n",
        "\n",
        "    main_l = Dense(128)(main_l)\n",
        "    main_l = Activation('relu')(main_l)\n",
        "\n",
        "    main_l = Dense(64)(main_l)\n",
        "    main_l = Activation('relu')(main_l)\n",
        "\n",
        "    # the output layer.\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model6()\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "brand_name (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_desc (InputLayer)          (None, 75)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "name (InputLayer)               (None, 8)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_27 (Embedding)        (None, 1, 10)        52900       brand_name[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_28 (Embedding)        (None, 1, 10)        110         subcat1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_29 (Embedding)        (None, 1, 10)        1140        subcat2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_30 (Embedding)        (None, 1, 10)        8830        subcat3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_26 (Embedding)        (None, 75, 60)       15545280    item_desc[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_25 (Embedding)        (None, 8, 50)        12954400    name[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 10)           0           embedding_27[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 10)           0           embedding_28[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_15 (Flatten)            (None, 10)           0           embedding_29[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_16 (Flatten)            (None, 10)           0           embedding_30[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "item_condition (InputLayer)     (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     (None, 16)           3696        embedding_26[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "gru_2 (GRU)                     (None, 8)            1416        embedding_25[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "num_vars (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 66)           0           flatten_13[0][0]                 \n",
            "                                                                 flatten_14[0][0]                 \n",
            "                                                                 flatten_15[0][0]                 \n",
            "                                                                 flatten_16[0][0]                 \n",
            "                                                                 item_condition[0][0]             \n",
            "                                                                 gru_1[0][0]                      \n",
            "                                                                 gru_2[0][0]                      \n",
            "                                                                 num_vars[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 512)          34304       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 512)          0           dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 256)          131328      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 256)          0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 128)          32896       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 128)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 64)           8256        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64)           0           dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 1)            65          activation_16[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 28,774,621\n",
            "Trainable params: 28,774,621\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqDd8RDFaC1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 1000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model6()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlpJs__FaGDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcYWkcXac3Il",
        "colab_type": "text"
      },
      "source": [
        "Prvotno su išle aktivacijske funkcije redom: sigmoid, tanh, relu, relu.\n",
        "\n",
        "Nakon 5 epoha: RMSLE na validacijskom: 0.4766091084883943\n",
        " \n",
        " Nakon 4 epohe:  RMSLE na validacijskom: 0.46666912700339036\n",
        " \n",
        " Ako stavim sve aktivacijske funkcije da budu 'relu'\n",
        " \n",
        " Nakon 4 epohe:  RMSLE na validacijskom: 0.4488953920679439\n",
        " \n",
        " Nakon 5 epoha:  RMSLE na validacijskom: 0.442122862243461"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psSg5eBK7qHS",
        "colab_type": "text"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swuc71dLGJEg",
        "colab_type": "code",
        "outputId": "67591a34-06a1-415f-dc8e-5e7ebcbc3a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1490
        }
      },
      "source": [
        "#KERAS MODEL DEFINITION\n",
        "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, Conv1D, GlobalMaxPooling1D, Embedding, Flatten, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def get_model7():\n",
        "    #params\n",
        "    dr_r = 0.5\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[1], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 50)(brand_name)\n",
        "    emb_subcat_1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat_2 = Embedding(MAX_CAT2, 20)(subcat2)\n",
        "    emb_subcat_3 = Embedding(MAX_CAT3, 30)(subcat3)\n",
        "\n",
        " \n",
        "    #rnn layer\n",
        "    cnn_layer1 = Conv1D(filters=16, kernel_size=3, activation='relu') (emb_item_desc)\n",
        "    cnn_layer2 = Conv1D(filters=8, kernel_size=3, activation='relu')(emb_name)\n",
        "    \n",
        "    cnn_layer1 = GlobalMaxPooling1D()(cnn_layer1)\n",
        "    cnn_layer2 = GlobalMaxPooling1D()(cnn_layer2)\n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name)\n",
        "        , Flatten() (emb_subcat_1)\n",
        "        , Flatten() (emb_subcat_2)\n",
        "        , Flatten() (emb_subcat_3)\n",
        "        , cnn_layer1\n",
        "        , cnn_layer2\n",
        "        , num_vars\n",
        "        , item_condition\n",
        "    ])\n",
        "    \n",
        "    main_l = Dropout(dr_r) (Dense(256, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(128, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(64, activation=\"relu\") (main_l))\n",
        "    \n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    \n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model\n",
        "\n",
        "    \n",
        "model = get_model7()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "item_desc (InputLayer)          (None, 75)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "name (InputLayer)               (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "brand_name (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 75, 50)       12954400    item_desc[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 10, 50)       12954400    name[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 50)        264500      brand_name[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 10)        110         subcat1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 20)        2280        subcat2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 1, 30)        26490       subcat3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 73, 16)       2416        embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 8, 8)         1208        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 50)           0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 10)           0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 20)           0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 30)           0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 16)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 8)            0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "num_vars (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_condition (InputLayer)     (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 136)          0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 num_vars[0][0]                   \n",
            "                                                                 item_condition[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          35072       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            65          dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,282,093\n",
            "Trainable params: 26,282,093\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeVERAdY8suJ",
        "colab_type": "code",
        "outputId": "1270c8d8-3077-4d58-e838-2fc64dc8a91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 15\n",
        "\n",
        "model = get_model7()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1467709 samples, validate on 14826 samples\n",
            "Epoch 1/15\n",
            "1467709/1467709 [==============================] - 238s 162us/step - loss: 0.0322 - mean_absolute_error: 0.1368 - rmsle_cust: 0.0165 - val_loss: 0.0193 - val_mean_absolute_error: 0.1087 - val_rmsle_cust: 0.0139\n",
            "Epoch 2/15\n",
            "1467709/1467709 [==============================] - 235s 160us/step - loss: 0.0181 - mean_absolute_error: 0.1024 - rmsle_cust: 0.0138 - val_loss: 0.0165 - val_mean_absolute_error: 0.0978 - val_rmsle_cust: 0.0143\n",
            "Epoch 3/15\n",
            "1467709/1467709 [==============================] - 236s 160us/step - loss: 0.0156 - mean_absolute_error: 0.0947 - rmsle_cust: 0.0130 - val_loss: 0.0156 - val_mean_absolute_error: 0.0952 - val_rmsle_cust: 0.0138\n",
            "Epoch 4/15\n",
            "1467709/1467709 [==============================] - 236s 161us/step - loss: 0.0141 - mean_absolute_error: 0.0901 - rmsle_cust: 0.0126 - val_loss: 0.0152 - val_mean_absolute_error: 0.0934 - val_rmsle_cust: 0.0135\n",
            "Epoch 5/15\n",
            "1467709/1467709 [==============================] - 236s 161us/step - loss: 0.0131 - mean_absolute_error: 0.0867 - rmsle_cust: 0.0122 - val_loss: 0.0147 - val_mean_absolute_error: 0.0919 - val_rmsle_cust: 0.0128\n",
            "Epoch 6/15\n",
            "1467709/1467709 [==============================] - 235s 160us/step - loss: 0.0123 - mean_absolute_error: 0.0840 - rmsle_cust: 0.0119 - val_loss: 0.0146 - val_mean_absolute_error: 0.0913 - val_rmsle_cust: 0.0126\n",
            "Epoch 7/15\n",
            "1467709/1467709 [==============================] - 235s 160us/step - loss: 0.0117 - mean_absolute_error: 0.0817 - rmsle_cust: 0.0116 - val_loss: 0.0143 - val_mean_absolute_error: 0.0898 - val_rmsle_cust: 0.0122\n",
            "Epoch 8/15\n",
            "1467709/1467709 [==============================] - 235s 160us/step - loss: 0.0112 - mean_absolute_error: 0.0798 - rmsle_cust: 0.0113 - val_loss: 0.0144 - val_mean_absolute_error: 0.0905 - val_rmsle_cust: 0.0122\n",
            "Epoch 9/15\n",
            "1467709/1467709 [==============================] - 236s 161us/step - loss: 0.0107 - mean_absolute_error: 0.0782 - rmsle_cust: 0.0112 - val_loss: 0.0144 - val_mean_absolute_error: 0.0902 - val_rmsle_cust: 0.0121\n",
            "Epoch 10/15\n",
            "1467709/1467709 [==============================] - 236s 160us/step - loss: 0.0104 - mean_absolute_error: 0.0769 - rmsle_cust: 0.0110 - val_loss: 0.0144 - val_mean_absolute_error: 0.0902 - val_rmsle_cust: 0.0121\n",
            "Epoch 11/15\n",
            "1467709/1467709 [==============================] - 236s 161us/step - loss: 0.0101 - mean_absolute_error: 0.0757 - rmsle_cust: 0.0108 - val_loss: 0.0145 - val_mean_absolute_error: 0.0906 - val_rmsle_cust: 0.0121\n",
            "Epoch 12/15\n",
            "1467709/1467709 [==============================] - 236s 161us/step - loss: 0.0098 - mean_absolute_error: 0.0746 - rmsle_cust: 0.0107 - val_loss: 0.0145 - val_mean_absolute_error: 0.0905 - val_rmsle_cust: 0.0119\n",
            "Epoch 13/15\n",
            "1467709/1467709 [==============================] - 236s 161us/step - loss: 0.0096 - mean_absolute_error: 0.0737 - rmsle_cust: 0.0106 - val_loss: 0.0146 - val_mean_absolute_error: 0.0906 - val_rmsle_cust: 0.0122\n",
            "Epoch 14/15\n",
            "1467709/1467709 [==============================] - 236s 161us/step - loss: 0.0094 - mean_absolute_error: 0.0729 - rmsle_cust: 0.0105 - val_loss: 0.0146 - val_mean_absolute_error: 0.0911 - val_rmsle_cust: 0.0119\n",
            "Epoch 15/15\n",
            "1467709/1467709 [==============================] - 236s 161us/step - loss: 0.0092 - mean_absolute_error: 0.0721 - rmsle_cust: 0.0104 - val_loss: 0.0146 - val_mean_absolute_error: 0.0907 - val_rmsle_cust: 0.0120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6405777e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVu1POp7899e",
        "colab_type": "code",
        "outputId": "8224dd4b-3374-47d5-9b45-46b446341385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#EVALUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.48178611835213986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smCo4Sxdi7Oq",
        "colab_type": "text"
      },
      "source": [
        "Nakon 15 epoha:  RMSLE na validacijskom: 0.48178611835213986\n",
        "\n",
        "Nakon 10 epoha:  RMSLE na validacijskom: 0.4927266404259878\n",
        "\n",
        "Nakon 5 epoha:  RMSLE na validacijskom: 0.5118675884280706"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b6QA98s8eFa",
        "colab_type": "text"
      },
      "source": [
        "Ako promijenim broj filtera na cnn_layer2 a 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hWUm9LGrkj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#KERAS MODEL DEFINITION\n",
        "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, Conv1D, GlobalMaxPooling1D, Embedding, Flatten, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def get_model8():\n",
        "    #params\n",
        "    dr_r = 0.5\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[1], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 50)(brand_name)\n",
        "    emb_subcat_1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat_2 = Embedding(MAX_CAT2, 20)(subcat2)\n",
        "    emb_subcat_3 = Embedding(MAX_CAT3, 30)(subcat3)\n",
        "\n",
        " \n",
        "    #rnn layer\n",
        "    cnn_layer1 = Conv1D(filters=16, kernel_size=3, activation='relu') (emb_item_desc)\n",
        "    cnn_layer2 = Conv1D(filters=16, kernel_size=3, activation='relu')(emb_name)\n",
        "    \n",
        "    cnn_layer1 = GlobalMaxPooling1D()(cnn_layer1)\n",
        "    cnn_layer2 = GlobalMaxPooling1D()(cnn_layer2)\n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name)\n",
        "        , Flatten() (emb_subcat_1)\n",
        "        , Flatten() (emb_subcat_2)\n",
        "        , Flatten() (emb_subcat_3)\n",
        "        , cnn_layer1\n",
        "        , cnn_layer2\n",
        "        , num_vars\n",
        "        , item_condition\n",
        "    ])\n",
        "    \n",
        "    main_l = Dropout(dr_r) (Dense(256, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(128, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(64, activation=\"relu\") (main_l))\n",
        "    \n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    \n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model\n",
        "\n",
        "    \n",
        "model = get_model8()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I6B42Twrzhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 10\n",
        "\n",
        "model = get_model8()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVnWhD4Br5Tj",
        "colab_type": "code",
        "outputId": "891bcfaf-65e2-4735-dadb-6ae6ed585a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#EVALUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.48348509735603296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txs21OwOsAGa",
        "colab_type": "text"
      },
      "source": [
        "5 epoha: 0.49018418646992745\n",
        "\n",
        "\n",
        "10 epoha:  RMSLE na validacijskom: 0.48348509735603296\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PxPx9txxLWo",
        "colab_type": "text"
      },
      "source": [
        "Povećavam kernel size pri kreiranju cnn layera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmvzCCbCISAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model9():\n",
        "    #params\n",
        "    dr_r = 0.5\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[1], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 50)(brand_name)\n",
        "    emb_subcat_1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat_2 = Embedding(MAX_CAT2, 20)(subcat2)\n",
        "    emb_subcat_3 = Embedding(MAX_CAT3, 30)(subcat3)\n",
        "\n",
        " \n",
        "    #rnn layer\n",
        "    cnn_layer1 = Conv1D(filters=16, kernel_size=5, activation='relu') (emb_item_desc)\n",
        "    cnn_layer2 = Conv1D(filters=16, kernel_size=5, activation='relu')(emb_name)\n",
        "    \n",
        "    cnn_layer1 = GlobalMaxPooling1D()(cnn_layer1)\n",
        "    cnn_layer2 = GlobalMaxPooling1D()(cnn_layer2)\n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name)\n",
        "        , Flatten() (emb_subcat_1)\n",
        "        , Flatten() (emb_subcat_2)\n",
        "        , Flatten() (emb_subcat_3)\n",
        "        , cnn_layer1\n",
        "        , cnn_layer2\n",
        "        , num_vars\n",
        "        , item_condition\n",
        "    ])\n",
        "    \n",
        "    main_l = Dropout(dr_r) (Dense(256, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(128, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(64, activation=\"relu\") (main_l))\n",
        "    \n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    \n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model\n",
        "\n",
        "    \n",
        "model = get_model9()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo376LF6xW31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 15\n",
        "\n",
        "model = get_model9()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mRXeK2MxV49",
        "colab_type": "text"
      },
      "source": [
        "Nakon 5 epoha:  RMSLE na validacijskom: 0.49636820125708847\n",
        "\n",
        "Nakon 15 epoha:  RMSLE na validacijskom: 0.4859954799040339\n",
        "\n",
        "Ne dobijem ništa od povećavanja kernel size-a, odustajem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up9doY4MISs-",
        "colab_type": "text"
      },
      "source": [
        "Dodajem regularizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-dsM5IDIAUH",
        "colab_type": "code",
        "outputId": "87047e15-006f-4f91-ef2c-57c0b623948d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1672
        }
      },
      "source": [
        "#KERAS MODEL DEFINITION\n",
        "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, Conv1D, GlobalMaxPooling1D, Embedding, Flatten, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "\n",
        "def get_model10():\n",
        "    #params\n",
        "    dr_r = 0.5\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[1], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 50)(brand_name)\n",
        "    emb_subcat_1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat_2 = Embedding(MAX_CAT2, 20)(subcat2)\n",
        "    emb_subcat_3 = Embedding(MAX_CAT3, 30)(subcat3)\n",
        "\n",
        " \n",
        "    #rnn layer\n",
        "    cnn_layer1 = Conv1D(filters=16, kernel_size=3, activation='relu',kernel_regularizer=regularizers.l2(0.01)) (emb_item_desc)\n",
        "    cnn_layer2 = Conv1D(filters=16, kernel_size=3, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_name)\n",
        "    \n",
        "    cnn_layer1 = GlobalMaxPooling1D()(cnn_layer1)\n",
        "    cnn_layer2 = GlobalMaxPooling1D()(cnn_layer2)\n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name)\n",
        "        , Flatten() (emb_subcat_1)\n",
        "        , Flatten() (emb_subcat_2)\n",
        "        , Flatten() (emb_subcat_3)\n",
        "        , cnn_layer1\n",
        "        , cnn_layer2\n",
        "        , num_vars\n",
        "        , item_condition\n",
        "    ])\n",
        "    \n",
        "    main_l = Dropout(dr_r) (Dense(256, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(128, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(64, activation=\"relu\") (main_l))\n",
        "    \n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    \n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model\n",
        "\n",
        "    \n",
        "model = get_model10()\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 15:03:05.771106 139898051307392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0618 15:03:05.795740 139898051307392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0618 15:03:05.797505 139898051307392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0618 15:03:05.956928 139898051307392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0618 15:03:05.969228 139898051307392 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0618 15:03:06.063752 139898051307392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0618 15:03:06.104329 139898051307392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "item_desc (InputLayer)          (None, 75)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "name (InputLayer)               (None, 8)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "brand_name (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 75, 50)       12954400    item_desc[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 8, 50)        12954400    name[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 50)        264500      brand_name[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 10)        110         subcat1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 20)        2280        subcat2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 1, 30)        26490       subcat3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 73, 16)       2416        embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 6, 16)        2416        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 50)           0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 10)           0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 20)           0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 30)           0           embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 16)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 16)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "num_vars (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_condition (InputLayer)     (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 144)          0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 num_vars[0][0]                   \n",
            "                                                                 item_condition[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          37120       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            65          dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 26,285,349\n",
            "Trainable params: 26,285,349\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC6JKAEHIeG6",
        "colab_type": "code",
        "outputId": "f4e28ab3-e72b-4a59-c633-14fcb020aaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model10()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1408408 samples, validate on 74127 samples\n",
            "Epoch 1/5\n",
            "1408408/1408408 [==============================] - 199s 141us/step - loss: 0.2008 - mean_absolute_error: 0.1404 - rmsle_cust: 0.0168 - val_loss: 0.0475 - val_mean_absolute_error: 0.1162 - val_rmsle_cust: 0.0150\n",
            "Epoch 2/5\n",
            "1408408/1408408 [==============================] - 195s 139us/step - loss: 0.0277 - mean_absolute_error: 0.1087 - rmsle_cust: 0.0146 - val_loss: 0.0179 - val_mean_absolute_error: 0.0987 - val_rmsle_cust: 0.0137\n",
            "Epoch 3/5\n",
            "1408408/1408408 [==============================] - 197s 140us/step - loss: 0.0184 - mean_absolute_error: 0.1014 - rmsle_cust: 0.0139 - val_loss: 0.0162 - val_mean_absolute_error: 0.0944 - val_rmsle_cust: 0.0134\n",
            "Epoch 4/5\n",
            "1408408/1408408 [==============================] - 193s 137us/step - loss: 0.0170 - mean_absolute_error: 0.0977 - rmsle_cust: 0.0135 - val_loss: 0.0155 - val_mean_absolute_error: 0.0931 - val_rmsle_cust: 0.0128\n",
            "Epoch 5/5\n",
            "1408408/1408408 [==============================] - 196s 139us/step - loss: 0.0162 - mean_absolute_error: 0.0951 - rmsle_cust: 0.0132 - val_loss: 0.0151 - val_mean_absolute_error: 0.0916 - val_rmsle_cust: 0.0123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3be3935860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_HKmE0RIkZM",
        "colab_type": "code",
        "outputId": "ebb1d042-1555-4b6c-acd9-dcd821c62823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#EVALUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.4863006604782542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgvhqFO1Il8l",
        "colab_type": "text"
      },
      "source": [
        "5 epoha: RMSLE na validacijskom: 0.4838138394894774\n",
        "\n",
        "10 epoha: RMSLE na validacijskom: 0.4786297305794245\n",
        "\n",
        "15 epoha:  RMSLE na validacijskom: 0.4711620291410097\n",
        "\n",
        "20 epoha:  RMSLE na validacijskom: 0.47936733148934196\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACzQOIE6MaMw",
        "colab_type": "code",
        "outputId": "25771f86-fc11-4164-936c-d43fa7ee5a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1361
        }
      },
      "source": [
        "#KERAS MODEL DEFINITION\n",
        "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, Conv1D, GlobalMaxPooling1D, Embedding, Flatten, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "\n",
        "def get_model11():\n",
        "    #params\n",
        "    dr_r = 0.5\n",
        "    \n",
        "    #Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[1], name=\"num_vars\")\n",
        "    \n",
        "    #Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 64)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 64)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 64)(brand_name)\n",
        "    emb_subcat_1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat_2 = Embedding(MAX_CAT2, 20)(subcat2)\n",
        "    emb_subcat_3 = Embedding(MAX_CAT3, 30)(subcat3)\n",
        "\n",
        " \n",
        "    #rnn layer\n",
        "    cnn_layer1 = Conv1D(filters=16, kernel_size=3, activation='relu',kernel_regularizer=regularizers.l2(0.01)) (emb_item_desc)\n",
        "    cnn_layer2 = Conv1D(filters=16, kernel_size=3, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_name)\n",
        "    \n",
        "    cnn_layer1 = GlobalMaxPooling1D()(cnn_layer1)\n",
        "    cnn_layer2 = GlobalMaxPooling1D()(cnn_layer2)\n",
        "    \n",
        "    #main layer\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name)\n",
        "        , Flatten() (emb_subcat_1)\n",
        "        , Flatten() (emb_subcat_2)\n",
        "        , Flatten() (emb_subcat_3)\n",
        "        , cnn_layer1\n",
        "        , cnn_layer2\n",
        "        , num_vars\n",
        "        , item_condition\n",
        "    ])\n",
        "    \n",
        "    main_l = Dropout(dr_r) (Dense(256, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(128, activation=\"relu\") (main_l))\n",
        "    main_l = Dropout(dr_r) (Dense(64, activation=\"relu\") (main_l))\n",
        "    \n",
        "    \n",
        "    #output\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "    \n",
        "    #model\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "    \n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "    \n",
        "    return model\n",
        "\n",
        "    \n",
        "model = get_model11()\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "item_desc (InputLayer)          (None, 75)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "name (InputLayer)               (None, 8)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "brand_name (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_59 (Embedding)        (None, 75, 64)       16581632    item_desc[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_58 (Embedding)        (None, 8, 64)        16581632    name[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_60 (Embedding)        (None, 1, 64)        338560      brand_name[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_61 (Embedding)        (None, 1, 10)        110         subcat1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_62 (Embedding)        (None, 1, 20)        2280        subcat2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_63 (Embedding)        (None, 1, 30)        26490       subcat3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 73, 16)       3088        embedding_59[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 6, 16)        3088        embedding_58[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_37 (Flatten)            (None, 64)           0           embedding_60[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_38 (Flatten)            (None, 10)           0           embedding_61[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_39 (Flatten)            (None, 20)           0           embedding_62[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_40 (Flatten)            (None, 30)           0           embedding_63[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_9 (GlobalM (None, 16)           0           conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_10 (Global (None, 16)           0           conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "num_vars (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_condition (InputLayer)     (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 158)          0           flatten_37[0][0]                 \n",
            "                                                                 flatten_38[0][0]                 \n",
            "                                                                 flatten_39[0][0]                 \n",
            "                                                                 flatten_40[0][0]                 \n",
            "                                                                 global_max_pooling1d_9[0][0]     \n",
            "                                                                 global_max_pooling1d_10[0][0]    \n",
            "                                                                 num_vars[0][0]                   \n",
            "                                                                 item_condition[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 256)          40704       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 256)          0           dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 128)          32896       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 128)          0           dense_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 64)           8256        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 64)           0           dense_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 1)            65          dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 33,618,801\n",
            "Trainable params: 33,618,801\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuy3bPnWMiz0",
        "colab_type": "code",
        "outputId": "a480adeb-5514-4932-bafb-eb6fef8bd3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model11()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1408408 samples, validate on 74127 samples\n",
            "Epoch 1/5\n",
            "1408408/1408408 [==============================] - 232s 165us/step - loss: 0.1979 - mean_absolute_error: 0.1469 - rmsle_cust: 0.0173 - val_loss: 0.0428 - val_mean_absolute_error: 0.1240 - val_rmsle_cust: 0.0154\n",
            "Epoch 2/5\n",
            "1408408/1408408 [==============================] - 230s 164us/step - loss: 0.0264 - mean_absolute_error: 0.1124 - rmsle_cust: 0.0148 - val_loss: 0.0185 - val_mean_absolute_error: 0.1022 - val_rmsle_cust: 0.0142\n",
            "Epoch 3/5\n",
            "1408408/1408408 [==============================] - 230s 163us/step - loss: 0.0190 - mean_absolute_error: 0.1037 - rmsle_cust: 0.0140 - val_loss: 0.0167 - val_mean_absolute_error: 0.0971 - val_rmsle_cust: 0.0136\n",
            "Epoch 4/5\n",
            "1408408/1408408 [==============================] - 227s 161us/step - loss: 0.0175 - mean_absolute_error: 0.0995 - rmsle_cust: 0.0136 - val_loss: 0.0165 - val_mean_absolute_error: 0.0973 - val_rmsle_cust: 0.0132\n",
            "Epoch 5/5\n",
            "1408408/1408408 [==============================] - 226s 160us/step - loss: 0.0166 - mean_absolute_error: 0.0966 - rmsle_cust: 0.0133 - val_loss: 0.0154 - val_mean_absolute_error: 0.0925 - val_rmsle_cust: 0.0129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3bde7fd828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzv1z40UMmSL",
        "colab_type": "code",
        "outputId": "9141ce96-2800-4a3f-cbbc-de6babbea1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#EVALUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " RMSLE na validacijskom: 0.4877910134982936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYkz1dzCMnct",
        "colab_type": "text"
      },
      "source": [
        "S povećanim koeficijentima embeddinga, ista cnn daje sljedeće rezultate:\n",
        "\n",
        "Nakon 5 epoha: RMSLE na validacijskom: 0.47676170497333076\n",
        " tj veći nego prije."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yppiMLFEiSB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1527
        },
        "outputId": "7ce977f6-e49e-4b81-af27-6440fdaac8f0"
      },
      "source": [
        "\n",
        "#KERAS MODEL DEFINITION\n",
        "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, Conv1D, GlobalMaxPooling1D, Embedding, Flatten, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "\n",
        "def get_model12():    \n",
        "    # Inputs\n",
        "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
        "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
        "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
        "    subcat1 = Input(shape=[1], name=\"subcat1\")\n",
        "    subcat2 = Input(shape=[1], name=\"subcat2\")\n",
        "    subcat3 = Input(shape=[1], name=\"subcat3\")\n",
        "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
        "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
        "\n",
        "    # Embeddings layers\n",
        "    emb_name = Embedding(MAX_TEXT, 50)(name)\n",
        "    emb_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n",
        "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
        "    emb_subcat1 = Embedding(MAX_CAT1, 10)(subcat1)\n",
        "    emb_subcat2 = Embedding(MAX_CAT2, 10)(subcat2)\n",
        "    emb_subcat3 = Embedding(MAX_CAT3, 10)(subcat3)\n",
        "    \n",
        "    cnn_layer1 = Conv1D(filters=16, kernel_size=3, activation='relu',kernel_regularizer=regularizers.l2(0.01)) (emb_item_desc)\n",
        "    cnn_layer2 = Conv1D(filters=16, kernel_size=3, activation='relu',kernel_regularizer=regularizers.l2(0.01))(emb_name)\n",
        "    \n",
        "    cnn_layer1 = GlobalMaxPooling1D()(cnn_layer1)\n",
        "    cnn_layer2 = GlobalMaxPooling1D()(cnn_layer2)\n",
        "\n",
        "    # main layers\n",
        "    main_l = concatenate([\n",
        "        Flatten() (emb_brand_name),\n",
        "        Flatten() (emb_subcat1),\n",
        "        Flatten() (emb_subcat2),\n",
        "        Flatten() (emb_subcat3),\n",
        "        item_condition,\n",
        "        cnn_layer1,\n",
        "        cnn_layer2,\n",
        "        num_vars,\n",
        "    ])\n",
        "    \n",
        "    main_l = Dense(512)(main_l)\n",
        "    main_l = Activation('relu')(main_l)\n",
        "    \n",
        "    main_l = Dense(256)(main_l)\n",
        "    main_l = Activation('relu')(main_l)\n",
        "\n",
        "    main_l = Dense(128)(main_l)\n",
        "    main_l = Activation('relu')(main_l)\n",
        "\n",
        "    main_l = Dense(64)(main_l)\n",
        "    main_l = Activation('relu')(main_l)\n",
        "\n",
        "    # the output layer.\n",
        "    output = Dense(1, activation=\"linear\") (main_l)\n",
        "\n",
        "    model = Model([name, item_desc, brand_name, subcat1, subcat2, subcat3, item_condition, num_vars], output)\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model12()\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 20:38:25.536352 140084485093248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0618 20:38:25.578406 140084485093248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "item_desc (InputLayer)          (None, 75)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "name (InputLayer)               (None, 8)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "brand_name (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat1 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "subcat3 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 75, 60)       15545280    item_desc[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 8, 50)        12954400    name[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 1, 10)        52900       brand_name[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, 1, 10)        110         subcat1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 1, 10)        1140        subcat2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 1, 10)        8830        subcat3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 73, 16)       2896        embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 6, 16)        2416        embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 10)           0           embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 10)           0           embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 10)           0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 10)           0           embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "item_condition (InputLayer)     (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 16)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 16)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "num_vars (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 74)           0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 item_condition[0][0]             \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 num_vars[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          38400       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          131328      activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 128)          32896       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128)          0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 64)           8256        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64)           0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            65          activation_4[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 28,778,917\n",
            "Trainable params: 28,778,917\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKhxlUNQiiq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 10000\n",
        "epochs = 5\n",
        "\n",
        "model = get_model12()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sibKClJ2ix9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EVALUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyXgQGtuxvZh",
        "colab_type": "text"
      },
      "source": [
        "Nakon 5 epoha:  RMSLE na validacijskom: 0.45740166297725926\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJMgJxMH71Xa",
        "colab_type": "text"
      },
      "source": [
        "## Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQiLQE9p7uRK",
        "colab_type": "code",
        "outputId": "9ee1d52b-5162-48e1-936c-eaa7ca8bc228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from gensim.models import word2vec\n",
        "import re\n",
        "sentences = [s for s in [s.strip().lower().split(\" \") for i in data[\"item_description\"].values for s in re.split(\"\\.\", str(i))] if len(s) > 2]\n",
        "embedding_size = 300\n",
        "starttime = time.time()\n",
        "model = word2vec.Word2Vec(sentences, size=embedding_size, window=5, min_count=5, workers=4)\n",
        "endtime = time.time()\n",
        "print(\"Trained word2vec model in \" + str(int(np.floor((endtime - starttime)/60))) + \"m \" + str(int((endtime - starttime)%60)) + \"s.\")\n",
        "\n",
        "# Get the embeddings into a matrix\n",
        "embedding_matrix = np.zeros((len(model.wv.index2word), embedding_size))\n",
        "for i in range(0, len(model.wv.index2word)):\n",
        "    w = model.wv.index2word[i]\n",
        "    embedding_matrix[i] = model.wv[w]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained word2vec model in 7m 43s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Tqq5qYLrIr",
        "colab_type": "code",
        "outputId": "a78ea3c0-7629-4d75-edfd-c2af476c207f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99843, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3LCsRd_WS7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "def truncated_normal(seed):\n",
        "    return keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss-10ezTSBCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create cnn model\n",
        "from keras.layers import Embedding, Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Concatenate, Dropout\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20) #20 najčešćih riječi\n",
        "\n",
        "# parameters\n",
        "input_length = pad_sequences(tokenizer.texts_to_sequences(data['item_description'].astype(str).tolist())).shape[1] # len (num words) of longest description\n",
        "seed = 0\n",
        "filter_sizes = [2,3]\n",
        "n_filters = 2\n",
        "dropout_prob = 0.5\n",
        "EMBEDDING_DIM=300\n",
        "\n",
        "def create_cnn(include_top=True, weights=None):    \n",
        "\n",
        "    # input\n",
        "    sequence_input = Input(shape=(input_length,), dtype='int32', name='input')\n",
        "    # embedding_layer\n",
        "    embedding_layer = Embedding(99843, EMBEDDING_DIM, weights=[embedding_matrix], input_length=input_length\n",
        "                                , name='embedding', trainable=False)(sequence_input)\n",
        "    # conv layer\n",
        "    features = []\n",
        "    i = 0\n",
        "    for filter_size in filter_sizes:\n",
        "        i += 1\n",
        "        # conv layer\n",
        "        conv = Conv1D(n_filters, filter_size, activation='relu', kernel_initializer=truncated_normal(seed)\n",
        "                      , name='conv'+str(i))(embedding_layer)\n",
        "        # global max pooling\n",
        "        conv = GlobalMaxPooling1D(name='pool'+str(i))(conv)\n",
        "        # add features together\n",
        "        features.append(conv)\n",
        "    # penultimate layer\n",
        "    nn = Concatenate(name='features')(features)\n",
        "    if include_top:\n",
        "        # dropout\n",
        "        nn = Dropout(dropout_prob, seed=seed, name='dropout')(nn)\n",
        "        # fully connected layer\n",
        "        preds = Dense(1, kernel_initializer=truncated_normal(seed), name='output')(nn)\n",
        "\n",
        "        model = Model(sequence_input, preds)\n",
        "    else:\n",
        "        model = Model(sequence_input, nn)\n",
        "    \n",
        "    \n",
        "    if weights is not None:\n",
        "        model.set_weights(weights)\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp6OueF1TwQe",
        "colab_type": "code",
        "outputId": "e1da73dc-9dfd-4282-82e9-aed43c813427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "model = create_cnn()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 0 for 'conv1/convolution' (op: 'Conv2D') with input shapes: [?,1,0,300], [1,2,300,2].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-3cfb07ea73fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-d2780990a457>\u001b[0m in \u001b[0;36mcreate_cnn\u001b[0;34m(include_top, weights)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# conv layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         conv = Conv1D(n_filters, filter_size, activation='relu', kernel_initializer=truncated_normal(seed)\n\u001b[0;32m---> 30\u001b[0;31m                       , name='conv'+str(i))(embedding_layer)\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# global max pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pool'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 dilation_rate=self.dilation_rate[0])\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             outputs = K.conv2d(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3609\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3611\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format, filters, dilations)\u001b[0m\n\u001b[1;32m    892\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    969\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    972\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1625\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m   1072\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 0 for 'conv1/convolution' (op: 'Conv2D') with input shapes: [?,1,0,300], [1,2,300,2]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICC1FqfhWczd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EVALUEATE THE MODEL ON DEV TEST: What is it doing?\n",
        "val_preds = model.predict(X_valid)\n",
        "val_preds = target_scaler.inverse_transform(val_preds)\n",
        "val_preds = np.exp(val_preds)+1\n",
        "\n",
        "#mean_absolute_error, mean_squared_log_error\n",
        "y_true = np.array(dvalid.price.values)\n",
        "y_pred = val_preds[:,0]\n",
        "v_rmsle = rmsle(y_true, y_pred)\n",
        "print(\" RMSLE na validacijskom: \"+str(v_rmsle))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7AUTH1aZ2qH",
        "colab_type": "text"
      },
      "source": [
        "## Word2vec pokusaj 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pZZzhU2aQOn",
        "colab_type": "text"
      },
      "source": [
        "https://blog.cambridgespark.com/tutorial-build-your-own-embedding-and-use-it-in-a-neural-network-e9cde4a81296"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEH4rlb4A7q0",
        "colab_type": "text"
      },
      "source": [
        " Potrebno je downloadati  ‘brown’ i ‘conll2000’ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naPN_eHLZ558",
        "colab_type": "code",
        "outputId": "1b44d12a-2dc1-4425-eb8a-e69a80a95626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.corpus import brown\n",
        "from gensim.models import word2vec\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> brown\n",
            "    Downloading package brown to /root/nltk_data...\n",
            "      Package brown is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> conll2000\n",
            "    Downloading package conll2000 to /root/nltk_data...\n",
            "      Package conll2000 is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OM1LT9oaN0F",
        "colab_type": "code",
        "outputId": "08b3ad43-c37c-49af-819e-01e46e94e5e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "sentences=brown.sents()\n",
        "print(sentences[:3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ['The', 'September-October', 'term', 'jury', 'had', 'been', 'charged', 'by', 'Fulton', 'Superior', 'Court', 'Judge', 'Durwood', 'Pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'Mayor-nominate', 'Ivan', 'Allen', 'Jr.', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9QzqPjXaek4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMB_DIM=300\n",
        "w2v= Word2Vec(sentences, size=EMB_DIM, window=5, min_count=5, negative=15, iter=10, workers=multiprocessing.cpu_count())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT1uqXDzaxvR",
        "colab_type": "code",
        "outputId": "835009c1-022b-46b5-a820-d76f574ffa77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "word_vectors=w2v.wv\n",
        "result=word_vectors.similar_by_word(\"Saturday\")\n",
        "print(\"Most similar word\", result[:3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most similar word [('Monday', 0.8954941630363464), ('Sunday', 0.8876497745513916), ('Friday', 0.8775694370269775)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCXiJ3vGHmaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list=dtrain['item_description'].astype(str).tolist()\n",
        "list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLfrOFEQIRVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re #za regularne izraze\n",
        "sentences = [s for s in [s.strip().lower().split(\" \") for i in dtrain[\"item_description\"].values for s in re.split(\"\\.\", str(i))] if len(s) > 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCrFsJYYKEjZ",
        "colab_type": "code",
        "outputId": "8b5762fa-4676-413d-a367-bc73f63eaeb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embedding_size = 300\n",
        "starttime = time.time()\n",
        "model = word2vec.Word2Vec(sentences, size=embedding_size, window=5, min_count=5, workers=4)\n",
        "endtime = time.time()\n",
        "print(\"Trained word2vec model in \" + str(int(np.floor((endtime - starttime)/60))) + \"m \" + str(int((endtime - starttime)%60)) + \"s.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained word2vec model in 7m 41s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnRcjaY4LFbe",
        "colab_type": "code",
        "outputId": "c6f0f7d4-3d9c-4101-e541-4aa958fa0a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3286
        }
      },
      "source": [
        "# First get the embeddings into a matrix\n",
        "embeddings = np.zeros((len(model.wv.index2word), embedding_size))\n",
        "for i in range(0, len(model.wv.index2word)):\n",
        "    w = model.wv.index2word[i]\n",
        "    embeddings[i] = model.wv[w]\n",
        "\n",
        "# Look at a few samples\n",
        "for i in range(1000, 1003):\n",
        "    print(model.wv.index2word[i] + \":\\n\" + str(embeddings[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "brands:\n",
            "[ 0.44668913  1.00813818 -0.22744668 -0.9685902  -3.41443086 -3.16814089\n",
            " -0.22257502 -0.03917033 -1.22988534  2.18945885 -2.84362912 -0.19964619\n",
            " -1.58515918  1.42916739 -3.25213361 -0.23979598 -0.2544238  -1.33195376\n",
            " -0.42963734 -0.7462576   0.07675014 -2.65952826 -0.24966502  1.64022124\n",
            "  0.86781543  2.54823875 -1.04541171  1.30657816 -0.19551505 -3.35859537\n",
            "  2.30055141  0.33194959 -0.98279977 -1.50124264  2.85995841  1.21530592\n",
            "  0.641653   -1.72203624  3.25559616  1.94765139  0.93429691 -2.79589486\n",
            "  0.42177838  0.43948707 -2.44652176  1.93160319 -0.3613373  -1.74829733\n",
            " -0.16010456 -0.11765492  0.86090881 -0.98350197 -0.10672019 -0.05587982\n",
            " -1.39775884  1.96347141 -1.01379275 -3.33755255 -0.76610672 -0.12707937\n",
            " -1.07743227  0.20845501  0.20666289 -0.21156941 -2.97382569  0.17074463\n",
            " -1.6924746  -1.07575905 -1.46513724 -0.47477415 -2.75424218  0.16317828\n",
            " -1.61430883 -2.18920207 -1.12000692  1.45951211  0.5928722  -0.8480345\n",
            "  2.01112962  0.46623895 -1.7516222  -1.54059136 -0.08235955 -0.52546662\n",
            "  0.39146757 -1.89372516 -0.55339098  0.72372758  1.09829569 -0.10836525\n",
            " -1.21597004  0.37208444 -2.36603665 -0.07611614  3.15984201  0.23519798\n",
            "  1.96332026 -1.15733385 -0.71059406 -0.54488862 -3.17107844  0.75455761\n",
            " -0.46773216 -0.60403627  0.28875938 -2.67708731  1.31708038 -0.69561201\n",
            " -1.19647312  0.16561033  0.24957649 -2.15828681  0.08490024 -1.48525333\n",
            " -1.89121997 -0.1777225   1.57291865 -1.37039149 -1.54752338  0.02010131\n",
            " -0.16574737 -0.81385273 -3.30389428  1.53949916 -2.4160037   0.07415876\n",
            "  0.13363072 -1.91616797 -0.50524372  0.45497477  0.4256207   0.35843384\n",
            " -2.0712409  -0.83445001  0.78062069  2.34013391  0.55946141 -0.68976462\n",
            "  0.3406364   0.18021321  1.24182916 -0.43104476  1.44175446  0.38249961\n",
            " -0.1150377   2.2407918   0.53383559  0.95225888  1.87047172  1.51345313\n",
            " -0.51783174 -1.09212387 -1.78748357  1.56519759 -1.49065983  0.50532889\n",
            "  1.19100535 -1.06589377  0.14383459 -0.29959708 -1.81094372  0.66200805\n",
            "  1.26903939  1.42876315  0.65846789  0.80855381  3.82354116 -0.63642061\n",
            "  1.45343828 -0.5615052   0.8898344  -2.35285425 -2.23439169  1.37127674\n",
            "  1.53176498 -0.92329091  3.19727683  0.91152632  2.97246814 -1.46392596\n",
            "  0.1840713  -0.08409934 -1.23596501  0.45804372  3.32611728  1.07301307\n",
            "  0.23419601  0.57452309  2.65162373 -0.42608467 -1.56777263  1.17090237\n",
            "  1.27765191 -0.19231452 -0.4781487  -0.98583436 -0.86839992  0.11642868\n",
            " -0.8905257  -0.66900557 -0.64987159  2.57147384  1.44331646 -2.90878916\n",
            "  2.33809042  0.6647532  -0.94992793  1.48379183 -0.94486618  1.40419948\n",
            "  0.0647296   0.39524317 -0.16817938  2.59271145 -0.5637998   0.5721938\n",
            "  2.53698826 -0.98766667 -0.09308556  0.81121457 -0.06986738  0.5821625\n",
            " -0.54903722  0.16723044  0.87557912 -0.60646009 -0.13878229 -1.26045775\n",
            "  0.62900931 -0.10408957 -0.66036046  1.60427904 -1.97333205  0.58169216\n",
            " -0.55978769  0.94205225  0.85658431 -0.33078265 -0.95360178  1.20798826\n",
            " -1.06756723  0.21000466  0.71827072  0.40951514 -0.25683433 -0.34657621\n",
            " -2.57120848 -1.69009936  2.10612535  1.20000553  0.61388451  0.28450495\n",
            "  0.56107223 -2.85687923 -0.50073063 -1.3157717   0.88480222 -2.04394698\n",
            "  1.1609453  -3.13265228 -4.32173824 -1.70837855  0.29954982 -1.60251081\n",
            "  1.09207368  0.87578052  0.46530938  1.28558445 -0.07070418  0.27231199\n",
            " -0.19186138 -0.96673524  0.66417861 -0.10696004 -0.35945538 -2.63795781\n",
            " -1.21189046 -2.12130046 -0.24064328  0.06385183  1.79494095  0.26233718\n",
            "  1.55144286 -1.75638282  2.6523118  -0.93496203 -2.48938394  0.01522795\n",
            " -1.78223574 -0.73231143 -0.67869818  0.4153038   0.09377     0.22976008\n",
            " -0.75618815  0.28965414 -0.17386499  0.01948589 -0.11727035 -0.80093676]\n",
            "charcoal:\n",
            "[ 0.70596284  1.00132811  0.75720692 -0.41637477 -0.18294522 -0.32016975\n",
            " -0.24371803  0.25304148  0.8163982   0.93936455 -0.57654506 -0.03154634\n",
            " -0.89115828 -1.35976434  2.1839354  -0.83269119 -0.03946619  1.49052763\n",
            "  0.43220952 -1.78032899  1.57121611  0.89132583 -1.50907254 -0.74410379\n",
            "  1.20484376 -0.87336135  0.3975268  -0.05562218 -0.21105944  0.35086015\n",
            " -0.05299922  0.60839802  2.0541048  -0.42820925  0.22404487 -0.80292296\n",
            "  0.2567803   1.69204426 -0.80384934  0.35160094  0.04660327 -1.95369351\n",
            " -0.05622014 -1.69105518  0.53200328  0.33153692  1.39131713  1.24216473\n",
            " -2.13209867  1.69073057  2.55812836 -1.38467085  0.52021146 -0.52892154\n",
            "  0.25106072 -1.1634202  -2.33014536  0.45515203  0.09988213 -1.93541765\n",
            "  1.48148096  0.25118768  1.28639054 -0.35889697 -0.56333297 -2.95511293\n",
            " -1.44309354  0.81660348 -0.03038676 -1.01685739  0.35203481  1.20107377\n",
            "  0.44731772  0.71794701  0.61921102  1.45938313 -2.72015977 -0.57761621\n",
            " -0.40060988 -0.05318749 -1.16046655 -1.70017219 -1.08667707 -0.26204991\n",
            "  0.66352063 -0.10876747  0.81445062 -1.78425956  0.54722852  1.98166466\n",
            " -0.71744412 -0.00766991  0.57527953  0.19438967  0.32195154  0.61562234\n",
            " -0.65307617 -0.13882251 -0.69267571  0.90585601  0.29553276  0.13198806\n",
            " -0.9963842   0.88321203  1.9124155   1.71710217  0.81031632  1.11618912\n",
            "  2.1368444  -1.97852612  0.73315889  1.75275016  0.7733022  -0.23556864\n",
            "  0.23924688  0.49009225 -0.09247834  0.54115051 -0.34850904 -0.94970888\n",
            "  1.36280143 -0.78697467 -1.98191571 -2.53303027 -2.87881351 -0.32330012\n",
            "  1.01672077  0.4282892   0.97226894  0.19984944 -1.57141232 -0.30051595\n",
            "  0.28540584  3.03970432  2.47493792 -1.12578285 -1.71989155 -0.14798403\n",
            "  1.66322374 -0.11231231 -0.17826565  0.01995991 -0.57318491 -1.04458964\n",
            " -0.70668006 -0.29810166 -0.29192263 -1.75896072  0.08830455 -0.19944544\n",
            "  0.16927011 -0.26894435 -0.80879688  0.99204779  1.69008672  0.38908723\n",
            " -0.72216773 -0.45185778 -0.76803154 -2.66893888  0.67261434 -0.30638966\n",
            " -1.61599052  0.80375224  0.81706238  0.06064737 -1.26633477  0.67908108\n",
            "  1.80204082 -1.39294827  1.70073307  1.12214541  1.34679854  0.25949654\n",
            "  1.52556407 -2.78136444  2.65358329  0.24099655 -2.37808871 -1.94475627\n",
            "  0.47922149 -0.67977065  1.14298332 -0.22703741  2.76474857 -3.59722924\n",
            " -0.21895564 -1.58220351 -1.06722534  0.17937826  1.22369695  1.49336898\n",
            "  0.58660066 -1.26040971 -0.22028796  0.32629716 -0.79323775 -0.03437894\n",
            "  0.65855592 -0.04841273  0.12162827 -0.53803945  0.31168708 -1.64591122\n",
            "  0.46534082  1.67738056  1.61539543 -1.14160216  1.64520121  0.3852798\n",
            " -0.65925592  1.03168297  0.54225081  0.43052149 -1.60635519  0.47888839\n",
            "  0.00638097  0.43232042 -2.36216044  1.03703189  0.15817888  0.96976644\n",
            "  0.47492123 -1.99878705 -0.9483465  -0.72747523 -0.33519608 -2.18547106\n",
            " -0.80937499 -0.76513475 -0.23089713 -0.56364501  1.71652174 -0.7854116\n",
            "  0.86386615  0.20916453 -0.45881897  0.14347737  1.63416553  0.72237957\n",
            " -0.05702084  0.97658461  2.22279286 -0.19058894  0.26059291  0.65341365\n",
            " -0.18776882  2.21459508 -1.88606155  0.19276646 -1.87890208  1.13187134\n",
            " -1.50475657  0.87959456 -1.71615458 -0.93523884  1.05331349  0.1904874\n",
            "  1.11817276  1.6848563   3.04786539  1.42123353 -0.95413679 -0.0794491\n",
            "  2.77992654 -0.25619447  0.77855974 -1.1360122  -0.62771684  0.30979839\n",
            "  0.29144502 -0.08328636 -1.80038118  0.94710773 -0.95319092  1.27260578\n",
            "  0.78095633 -1.71200228  0.10007365  1.14934468 -0.48428154  1.54164958\n",
            " -0.64470452  0.3475914  -1.25264394  0.87922829 -1.19919884  1.11479521\n",
            " -1.21635354  2.45592618 -2.45216656 -1.76478589  1.31764328 -2.25450492\n",
            " -0.2436126   0.6791544  -1.36537158  1.2505188  -0.1458364   1.75286388]\n",
            "running:\n",
            "[-1.56385446e+00 -8.67163539e-01  4.69495654e-01  1.89339325e-01\n",
            "  9.66588378e-01  2.15436983e+00  1.15687430e+00  4.96525943e-01\n",
            " -5.43870926e-01 -8.27500761e-01  3.76679748e-02  4.87623811e-01\n",
            " -6.20489307e-02 -9.29240704e-01  1.65035820e+00 -7.00105548e-01\n",
            " -3.52778077e-01  1.15432811e+00 -5.70240438e-01  1.33447126e-01\n",
            " -6.64406657e-01  4.25671548e-01 -9.01005387e-01 -3.07116687e-01\n",
            " -6.80295229e-01  7.81166479e-02  1.24705851e+00 -2.39157796e-01\n",
            "  9.07775879e-01 -5.50259590e-01  1.55762184e+00  1.15634274e+00\n",
            "  6.49820805e-01  4.28815246e-01  1.30337358e+00  3.76022995e-01\n",
            "  1.23616743e+00  8.12410235e-01 -7.05312252e-01  1.34447527e+00\n",
            "  6.57171369e-01 -9.18096229e-02  4.56288069e-01  1.34510303e+00\n",
            "  1.73629439e+00  1.53291368e+00 -1.40735835e-01  1.34586751e+00\n",
            "  2.69050330e-01 -4.97452945e-01  1.22508667e-02 -2.53522277e+00\n",
            " -2.54962087e+00  1.17500490e-02 -6.22516163e-02  1.01191235e+00\n",
            "  1.75546277e+00 -7.18838751e-01 -1.22669208e+00 -1.57408571e+00\n",
            "  5.17521143e-01 -6.50852263e-01 -1.38817227e+00 -8.09754491e-01\n",
            "  6.90463126e-01 -1.13219142e+00 -1.76134661e-01 -5.26802361e-01\n",
            " -1.03300977e+00 -7.29269207e-01 -1.87592909e-01  8.94112587e-01\n",
            " -4.90048468e-01  1.38419783e+00  1.15286732e+00 -1.11123204e+00\n",
            " -5.45422554e-01 -5.73182523e-01  1.91048354e-01 -1.37584496e+00\n",
            " -1.19593143e+00  7.52941310e-01 -5.14777482e-01  1.39678872e+00\n",
            " -1.84994066e+00 -6.13814771e-01  1.95711792e+00  3.20104480e-01\n",
            "  5.94017327e-01 -1.23647797e+00  1.11270297e+00 -1.80983245e+00\n",
            "  2.22339332e-01 -1.06462038e+00  3.47571731e-01 -2.30860740e-01\n",
            "  9.24062788e-01  1.29687145e-01 -3.98001909e-01  7.36345768e-01\n",
            " -3.86711955e-01 -2.57920682e-01  3.32084626e-01 -1.46661937e-01\n",
            "  6.44457817e-01 -6.23511553e-01  1.51912355e+00 -1.30335093e+00\n",
            "  2.78972119e-01 -3.47203404e-01 -2.38323402e+00  1.31852853e+00\n",
            " -1.26740360e+00  7.22150683e-01 -2.72163600e-01  7.95455456e-01\n",
            " -1.61344614e-02  3.19483936e-01 -6.10094309e-01 -1.54288650e+00\n",
            "  2.33613968e+00  7.37338305e-01  1.10620332e+00  2.40812287e-01\n",
            "  1.64257860e+00 -6.48304701e-01  2.03783847e-02 -7.14918554e-01\n",
            " -3.77036110e-02  1.76817644e+00 -2.46176505e+00 -1.06636263e-01\n",
            " -5.25978625e-01 -1.29457366e+00 -1.33046007e+00 -1.92735747e-01\n",
            " -5.39319754e-01 -4.26024824e-01 -1.40893562e-02  9.02607858e-01\n",
            "  1.81309783e+00 -5.77688158e-01  9.89274681e-02  5.60264662e-02\n",
            "  8.62837076e-01 -2.40467206e-01 -6.75626278e-01 -5.51595390e-02\n",
            "  1.21659470e+00  9.08237517e-01  1.16941154e+00 -2.02251715e-03\n",
            "  1.06904626e+00  7.77309954e-01  3.25326502e-01  5.63127100e-01\n",
            "  2.96884980e-02  1.86999059e+00 -2.41108537e-02 -5.82803190e-02\n",
            "  2.61830181e-01 -1.10500240e+00 -5.73185980e-01 -8.30088258e-01\n",
            "  1.17417943e+00 -5.61777115e-01 -1.03799593e+00 -1.93429053e-01\n",
            "  5.03321886e-01 -1.93416044e-01  1.36735186e-01 -4.05629903e-01\n",
            " -9.31503356e-01 -9.63015854e-02 -2.46335104e-01 -4.41692680e-01\n",
            " -8.17832649e-01 -8.99972320e-01  1.49408841e+00 -2.03670287e+00\n",
            "  3.37060392e-01 -4.53209549e-01  4.75527614e-01  6.31859541e-01\n",
            " -5.28862894e-01  9.15778577e-01  6.32837653e-01  1.26620758e+00\n",
            "  1.38294220e-01 -1.62797391e+00  1.53006911e+00  1.46534890e-01\n",
            " -1.09955418e+00  2.44178340e-01 -1.36372674e+00  1.05154617e-02\n",
            " -1.92523265e+00 -3.74106795e-01  2.55199194e+00 -1.74067819e+00\n",
            "  1.43544900e+00  1.72119096e-01 -7.61701167e-01 -5.81498086e-01\n",
            " -4.87890877e-02 -8.14746499e-01  4.16895524e-02  1.11043811e+00\n",
            " -3.52506787e-02 -9.65780139e-01 -5.71568608e-01  1.20398939e+00\n",
            " -1.59652603e+00  2.18160868e+00 -2.39343238e+00  5.74681997e-01\n",
            "  2.17578602e+00  7.27830112e-01  3.45927447e-01 -1.65866882e-01\n",
            "  7.58016944e-01  2.82579958e-01  5.39464206e-02 -5.72787762e-01\n",
            " -1.02445066e+00 -7.30728686e-01  1.58347756e-01 -7.21444845e-01\n",
            " -3.04765135e-01  6.92665339e-01 -1.32714903e+00 -5.36214076e-02\n",
            "  1.32052207e+00 -2.75022119e-01  1.25305188e+00  7.93877244e-01\n",
            " -6.20717943e-01  2.04765320e-01  5.52747667e-01  1.24438369e+00\n",
            "  8.61798704e-01 -3.72897297e-01 -7.24955928e-03  9.14761722e-01\n",
            "  1.71003431e-01 -7.78935254e-01 -1.29093635e+00  2.42312267e-01\n",
            "  1.74580979e+00 -5.65290570e-01  7.80900478e-01  1.60776508e+00\n",
            "  5.68237640e-02  4.57756847e-01  2.37291932e+00 -1.18090272e+00\n",
            " -1.08605242e+00 -4.43327129e-01  2.42360920e-01  1.06586099e+00\n",
            "  1.43364859e+00 -9.35319245e-01  6.57162666e-01  3.77238244e-02\n",
            " -8.92249525e-01 -1.72069204e+00  8.79950762e-01 -1.57834485e-01\n",
            "  3.25246006e-01  1.43004727e+00 -1.06236637e+00  3.86059880e-01\n",
            " -1.29626751e-01  3.08658034e-01 -8.40784371e-01  3.72694522e-01\n",
            "  6.91053987e-01 -7.96668708e-01  6.58354938e-01  1.49066448e-01\n",
            "  2.41471022e-01 -1.44791579e+00 -3.47719014e-01  2.64250159e-01\n",
            "  1.19677849e-01  4.88908529e-01 -4.51253533e-01 -3.32072854e-01\n",
            "  3.09644759e-01  1.36622354e-01 -1.66822866e-01  4.45905119e-01\n",
            "  2.17851430e-01  1.65959799e+00 -1.98980832e+00  1.44598162e+00\n",
            "  5.49090505e-01  1.63027227e-01 -3.48483741e-01 -2.07725018e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7PXuS7dPMrf",
        "colab_type": "code",
        "outputId": "d861a4bd-523f-41eb-d6c5-d81844dba1b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96933, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePk9nBjHPYZ3",
        "colab_type": "text"
      },
      "source": [
        "Za vizualizaciju"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptgd-Y6GPTJ_",
        "colab_type": "code",
        "outputId": "c3634191-0436-4735-cec1-deaa0f4d4a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=500, random_state=101)\n",
        "embeddings_2d_projection = svd.fit_transform(embeddings)\n",
        "embeddings_2d_projection.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96933, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVHWxiLcQLbX",
        "colab_type": "code",
        "outputId": "7c985652-b9c6-4c51-e536-96261ee25c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "lookup_words = [\"shorts\", \"xbox\", \"shoes\"]\n",
        "words_to_visualize = [] # Save for visualization below\n",
        "\n",
        "for w in lookup_words:\n",
        "    print(w)\n",
        "    for s in model.wv.most_similar([w]):\n",
        "        print(s)\n",
        "        words_to_visualize.append(s[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shorts\n",
            "('shorts!', 0.77289879322052)\n",
            "('capris', 0.7676331400871277)\n",
            "('shorts,', 0.7595573663711548)\n",
            "('pants', 0.7148447036743164)\n",
            "('skort', 0.6574950218200684)\n",
            "('overalls', 0.656518280506134)\n",
            "('shorts-', 0.6516613960266113)\n",
            "('joggers', 0.6134329438209534)\n",
            "(\"capri's\", 0.6130681037902832)\n",
            "('shorts)', 0.6072177290916443)\n",
            "xbox\n",
            "('ps4', 0.6656961441040039)\n",
            "('ps3', 0.6522459983825684)\n",
            "('x-box', 0.6271170973777771)\n",
            "('-xbox', 0.6259353160858154)\n",
            "('playstation', 0.5802122354507446)\n",
            "('ps4,', 0.5763287544250488)\n",
            "('controller,', 0.5707730054855347)\n",
            "('sony', 0.5601280927658081)\n",
            "('battlefield', 0.5365286469459534)\n",
            "('xboxone', 0.5357046127319336)\n",
            "shoes\n",
            "('sneakers', 0.8067567348480225)\n",
            "('shoes!', 0.7545838356018066)\n",
            "('shoe', 0.6472645998001099)\n",
            "('sneaker', 0.6412380337715149)\n",
            "('shoes,', 0.6370909214019775)\n",
            "('sandals', 0.6274315118789673)\n",
            "('flats', 0.6270042657852173)\n",
            "('loafers', 0.6198732256889343)\n",
            "('boots', 0.5915223956108093)\n",
            "('sperrys', 0.5893703699111938)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuZbtlDwPiLe",
        "colab_type": "code",
        "outputId": "0569ebf1-aa33-4b2d-f142-8416a9133c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "sample = np.in1d(model.wv.index2word, words_to_visualize)\n",
        "x = embeddings_2d_projection[sample,0]\n",
        "y = embeddings_2d_projection[sample,1]\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.scatter(x, y)\n",
        "for i, txt in enumerate([model.wv.index2word[i] for i in np.where(sample)[0]]):\n",
        "    plt.annotate(txt, (x[i], y[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAGfCAYAAAAzqveOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pWYCnjVUUJq",
        "colab_type": "text"
      },
      "source": [
        "## Word2Vec pokušaj tri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T41EzY8MUX0D",
        "colab_type": "text"
      },
      "source": [
        "Slijedim https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sj_7_C8ScMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "from time import time  # To time our operations\n",
        "from collections import defaultdict  # For word frequency\n",
        "\n",
        "import spacy  # For preprocessing\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMjseiMrSnUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    if len(txt) > 2:\n",
        "        return ' '.join(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YDJOa5sSv7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in dtrain['item_description'])\n",
        "#brief_cleaning_valid = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in dvalid['item_description'])\n",
        "#brief_cleaning_test = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in test['item_description'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_NygzTuTNOJ",
        "colab_type": "code",
        "outputId": "5e0e727f-b321-4d17-ea5c-94bfb06350f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
        "#txt_valid = [cleaning(doc) for doc in nlp.pipe(brief_cleaning_valid, batch_size=5000, n_threads=-1)]\n",
        "#txt_test = [cleaning(doc) for doc in nlp.pipe(brief_cleaning_test, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything: 29.12 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xw3JcH2Tp0L",
        "colab_type": "code",
        "outputId": "c6ac5afd-0b64-46ca-fc21-8b02657df014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_clean = pd.DataFrame({'clean': txt})\n",
        "#valid_clean = pd.DataFrame({'clean': txt_valid})\n",
        "#test_clean = pd.DataFrame({'clean': txt_test})\n",
        "\n",
        "data_clean = data_clean.dropna().drop_duplicates()\n",
        "#valid_clean = valid_clean.dropna().drop_duplicates()\n",
        "#test_clean = test_clean.dropna().drop_duplicates()\n",
        "\n",
        "data_clean.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1133921, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZiYf0lgUBdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "#uzima listu riječi kao input i kreira relevantne fraze iz liste rečenica\n",
        "\n",
        "data_sent = [row.split() for row in data_clean['clean']]\n",
        "#valid_sent = [row.split() for row in valid_clean['clean']]\n",
        "#test_sent = [row.split() for row in test_clean['clean']]\n",
        "\n",
        "phrases = Phrases(data_sent, min_count=30, progress_per=10000)\n",
        "#valid_phrases = Phrases(valid_sent, min_count=30, progress_per=10000)\n",
        "#test_phrases = Phrases(test_sent, min_count=30, progress_per=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA9Vr2PtpfW7",
        "colab_type": "text"
      },
      "source": [
        "U ovoj ćeliji spremam phrases za poslije"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hfr9j3ApIzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# Store data (serialize)\n",
        "with open('phrases.pickle', 'wb') as handle:\n",
        "    pickle.dump(phrases, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('datasent.pickle', 'wb') as handle:\n",
        "    pickle.dump(data_sent, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVTidRqupagC",
        "colab_type": "text"
      },
      "source": [
        "Iduća ćelija je za loadanje phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfYGVKCJpPtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# Load data (deserialize)\n",
        "with open('phrases.pickle', 'rb') as handle:\n",
        "    phrases = pickle.load(handle)\n",
        "with open('datasent.pickle', 'rb') as handle:\n",
        "    data_sent = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCsuxRU4rORc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigram = Phraser(phrases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp-jC0M6U-i1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = bigram[data_sent]\n",
        "#valid_sentences = bigram[valid_sent]\n",
        "#test_sentences = bigram[test_sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovQ2gpilVLZJ",
        "colab_type": "code",
        "outputId": "c0e790fa-9899-406d-ca28-e9940b2f29e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro-UtpZ7VP1Y",
        "colab_type": "code",
        "outputId": "046b1588-cfdf-45dc-f9cf-3591f94f26de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['size',\n",
              " 'new',\n",
              " 'wear',\n",
              " 'brand',\n",
              " 'condition',\n",
              " 'free',\n",
              " 'shipping',\n",
              " 'rm',\n",
              " 'color',\n",
              " 'black']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVV9eZGxVT_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkCZrQFOVdQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAIhukSpV9nK",
        "colab_type": "text"
      },
      "source": [
        "**Parametri**\n",
        "\n",
        "min_count ->ignorira sve riječi kojih ima manje od min_count\n",
        "\n",
        "window-> maksimalna udaljenost između trenutne i predviđene riječi u rečenici.\n",
        "\n",
        "size->dimenzije feature vektora\n",
        "\n",
        "sample-> jako utjecajan parametar-> treshold za konfiguraciju koje visokofrekventne riječi budu downsamplane.\n",
        "\n",
        "alpha->learning rate, ne sjećam se više kako to prevodimo lol\n",
        "\n",
        "min_alpha->očito\n",
        "\n",
        "negative-> ako je >0, koristit će se negativno uzorkovanje\n",
        "\n",
        "workers->koliko threadova za treniranje modela"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpwVtpFLg_Aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = Word2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQWUMCHUhExu",
        "colab_type": "code",
        "outputId": "b91d2c71-1270-4a7a-894f-6cb77744b08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 1.14 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UrOJXIcsmA9",
        "colab_type": "code",
        "outputId": "8938c0b5-5ba0-4f39-ca23-808ff7ed1945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=10, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to train the model: 19.19 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zq2IKaPs0L8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2FKouOis-Xj",
        "colab_type": "code",
        "outputId": "15d3570e-b920-46b9-d957-308cf9983507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"necklace\"])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bracelet', 0.724303126335144),\n",
              " ('pendant_necklace', 0.7080237865447998),\n",
              " ('earring', 0.6951838135719299),\n",
              " ('necklace_pendant', 0.675955593585968),\n",
              " ('pendant_chain', 0.6753482818603516),\n",
              " ('pendant', 0.6728875637054443),\n",
              " ('heart_pendant', 0.6675527095794678),\n",
              " ('pendent', 0.6639496088027954),\n",
              " ('multi_strand', 0.662032961845398),\n",
              " ('tibetan_silver', 0.659427285194397)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xR9HMWGtrHs",
        "colab_type": "code",
        "outputId": "a5ad2de6-afca-4c51-f60a-d8107dcd7c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# tokenize text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "n_words = 20 # top most common words\n",
        "text = data['item_description'].astype(str).tolist()\n",
        "tokenizer = Tokenizer(num_words=n_words)\n",
        "tokenizer.fit_on_texts(text)\n",
        "\n",
        "# pad_sequences so they are all of the same length\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(text) # list, same length as data. represent word as rank/index\n",
        "padded_seq = pad_sequences(sequences)\n",
        "print('padded_seq.shape', padded_seq.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "padded_seq.shape (1482535, 76)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqDOEk-k3G4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af639e9a-c948-4036-b0a6-5ea80d0d91fa"
      },
      "source": [
        "# kfold cv\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "x = padded_seq\n",
        "y = np.asarray(data['price'])\n",
        "\n",
        "n_splits = 2\n",
        "\n",
        "kf = KFold(n_splits=n_splits)\n",
        "kf.get_n_splits(x)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGhSrwJWt0Kk",
        "colab_type": "code",
        "outputId": "70f529d7-4792-4f5a-fb93-205e3d446965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# create embedding_matrix to feed in as weights for embedding_layer\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)\n",
        "EMBEDDING_DIM = 300 # this is from the pretrained vectors\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if word in w2v_model:\n",
        "        embedding_vector = w2v_model[word]\n",
        "    else:\n",
        "        embedding_vector = None\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Vx5dYOuZME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom loss function\n",
        "import keras.backend as K\n",
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
        "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
        "    \n",
        "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n",
        "\n",
        "import keras\n",
        "def truncated_normal(seed):\n",
        "    return keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlR-y8ZBud-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "1433745e-7f73-4e66-e6d2-5ad0ff9bf582"
      },
      "source": [
        "# create cnn model\n",
        "from keras.layers import Embedding, Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Concatenate, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "# parameters\n",
        "input_length = padded_seq.shape[1] # len (num words) of longest description\n",
        "seed = 0\n",
        "filter_sizes = [2,3]\n",
        "n_filters = 2\n",
        "dropout_prob = 0.5\n",
        "\n",
        "def create_cnn(include_top=True, weights=None):    \n",
        "\n",
        "    # input\n",
        "    sequence_input = Input(shape=(input_length,), dtype='int32', name='input')\n",
        "    # embedding_layer\n",
        "    embedding_layer = Embedding(vocab_size + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=input_length\n",
        "                                , name='embedding', trainable=False)(sequence_input)\n",
        "    # conv layer\n",
        "    features = []\n",
        "    i = 0\n",
        "    for filter_size in filter_sizes:\n",
        "        i += 1\n",
        "        # conv layer\n",
        "        conv = Conv1D(n_filters, filter_size, activation='relu', kernel_initializer=truncated_normal(seed)\n",
        "                      , name='conv'+str(i))(embedding_layer)\n",
        "        # global max pooling\n",
        "        conv = GlobalMaxPooling1D(name='pool'+str(i))(conv)\n",
        "        # add features together\n",
        "        features.append(conv)\n",
        "    # penultimate layer\n",
        "    nn = Concatenate(name='features')(features)\n",
        "    if include_top:\n",
        "        # dropout\n",
        "        nn = Dropout(dropout_prob, seed=seed, name='dropout')(nn)\n",
        "        # fully connected layer\n",
        "        preds = Dense(1, kernel_initializer=truncated_normal(seed), name='output')(nn)\n",
        "\n",
        "        model = Model(sequence_input, preds)\n",
        "    else:\n",
        "        model = Model(sequence_input, nn)\n",
        "    \n",
        "    \n",
        "    if weights is not None:\n",
        "        model.set_weights(weights)\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8886f451dc1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadded_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# len (num words) of longest description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfilter_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'padded_seq' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ9_6CDhugoK",
        "colab_type": "code",
        "outputId": "e1052b19-6ae7-4641-d5a1-f790077bcb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "model = create_cnn()\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 10:23:11.407020 139919915018112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0618 10:23:11.432275 139919915018112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0618 10:23:11.445360 139919915018112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0618 10:23:11.446398 139919915018112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0618 10:23:11.451052 139919915018112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0618 10:23:13.638352 139919915018112 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              (None, 76)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 76, 300)      62318100    input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv1D)                  (None, 75, 2)        1202        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv1D)                  (None, 74, 2)        1802        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (GlobalMaxPooling1D)      (None, 2)            0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool2 (GlobalMaxPooling1D)      (None, 2)            0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "features (Concatenate)          (None, 4)            0           pool1[0][0]                      \n",
            "                                                                 pool2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 4)            0           features[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            5           dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 62,321,109\n",
            "Trainable params: 3,009\n",
            "Non-trainable params: 62,318,100\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBU7Y1M06FvH",
        "colab_type": "code",
        "outputId": "b925b550-4506-459c-ce6c-45f2a41edffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "model.compile(loss='msle', optimizer='adadelta', metrics=[rmsle])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 10:23:13.686052 139919915018112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-ojsDua3fOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "f7e9f155-9893-4882-862f-0ceaaa3af4fc"
      },
      "source": [
        "# train cnn\n",
        "model.compile(loss='msle', optimizer='adadelta', metrics=[rmsle])\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "for train_index, val_index in kf.split(x):\n",
        "    x_train, x_val = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 09:16:48.562298 140048589928320 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 741267 samples, validate on 741268 samples\n",
            "Epoch 1/1\n",
            "741267/741267 [==============================] - 506s 683us/step - loss: 1.1197 - rmsle: 0.7922 - val_loss: 0.5571 - val_rmsle: 0.5746\n",
            "Train on 741268 samples, validate on 741267 samples\n",
            "Epoch 1/1\n",
            "741268/741268 [==============================] - 525s 708us/step - loss: 0.5910 - rmsle: 0.5932 - val_loss: 0.5549 - val_rmsle: 0.5764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXVotq02Yc7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "bee5e253-f6d9-4ff3-9264-7a05a5fc4d67"
      },
      "source": [
        "# train cnn\n",
        "model.compile(loss='msle', optimizer='adadelta', metrics=[rmsle])\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "for train_index, val_index in kf.split(x):\n",
        "    x_train, x_val = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 741267 samples, validate on 741268 samples\n",
            "Epoch 1/2\n",
            "741267/741267 [==============================] - 538s 726us/step - loss: 0.9182 - rmsle: 0.7279 - val_loss: 0.5575 - val_rmsle: 0.5748\n",
            "Epoch 2/2\n",
            "741267/741267 [==============================] - 573s 773us/step - loss: 0.5847 - rmsle: 0.5902 - val_loss: 0.5543 - val_rmsle: 0.5768\n",
            "Train on 741268 samples, validate on 741267 samples\n",
            "Epoch 1/2\n",
            "741268/741268 [==============================] - 535s 722us/step - loss: 0.5585 - rmsle: 0.5798 - val_loss: 0.5534 - val_rmsle: 0.5782\n",
            "Epoch 2/2\n",
            "741268/741268 [==============================] - 555s 749us/step - loss: 0.5556 - rmsle: 0.5796 - val_loss: 0.5534 - val_rmsle: 0.5785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho_lIqQ9LLTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "d6f7da94-afca-4dee-b360-0aadac1da555"
      },
      "source": [
        "# train cnn\n",
        "model.compile(loss='msle', optimizer='adadelta', metrics=[rmsle])\n",
        "\n",
        "batch_size = 10000\n",
        "epochs = 3\n",
        "for train_index, val_index in kf.split(x):\n",
        "    x_train, x_val = x[train_index], x[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 10:40:53.761055 139919915018112 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 741267 samples, validate on 741268 samples\n",
            "Epoch 1/3\n",
            "741267/741267 [==============================] - 449s 606us/step - loss: 7.0194 - rmsle: 2.4875 - val_loss: 3.8335 - val_rmsle: 1.7522\n",
            "Epoch 2/3\n",
            "741267/741267 [==============================] - 460s 621us/step - loss: 3.5646 - rmsle: 1.5904 - val_loss: 2.1264 - val_rmsle: 1.1812\n",
            "Epoch 3/3\n",
            "741267/741267 [==============================] - 465s 628us/step - loss: 2.6964 - rmsle: 1.3030 - val_loss: 1.5393 - val_rmsle: 0.9673\n",
            "Train on 741268 samples, validate on 741267 samples\n",
            "Epoch 1/3\n",
            "741268/741268 [==============================] - 458s 618us/step - loss: 2.3226 - rmsle: 1.1798 - val_loss: 1.2564 - val_rmsle: 0.8658\n",
            "Epoch 2/3\n",
            "741268/741268 [==============================] - 453s 611us/step - loss: 2.1180 - rmsle: 1.1144 - val_loss: 1.0924 - val_rmsle: 0.8084\n",
            "Epoch 3/3\n",
            "741268/741268 [==============================] - 465s 627us/step - loss: 1.9811 - rmsle: 1.0720 - val_loss: 0.9852 - val_rmsle: 0.7706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh-thdXI0umg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FITTING THE MODEL\n",
        "BATCH_SIZE = 1000\n",
        "epochs = 10\n",
        "\n",
        "model = create_cnn()\n",
        "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
        "          , validation_data=(X_valid, dvalid.target)\n",
        "          , verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}